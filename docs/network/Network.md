[toc]
# 一、网络协议栈

### OSI七层模型 TCP/IP四层模型

![](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7RBLjl-ZRtxDLHXqoQ%2F-M7Sehlg_jYuTq1xS0N9%2Fimage.png?alt=media&token=9166e612-f15a-47c1-b61c-18faf15142cc)


![模型对应层](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7QHP3q5XNIXHhFldtX%2F-M7Q_1l-BbWEiNwaIJ86%2Fimage.png?alt=media&token=187caea9-786c-4254-b038-49a66312ccb0)


‌

# 二、四层模型

### 2.0 四层模型
-   链路层
    -   包括操作系统中的驱动程序和计算机网卡还有传输的物理介质，链路层上面的主要协议有以太网协议。
-   网络层
    -   保证数据从一台主机将数据准确的发送到另一台指定的主机，主要通过指定IP地址（点分十进制）和端口号（表明应用程序）来实现，主要的协议有IP协议，ICMP和IGMP作为辅助协议。路由器属于网络层。
-   传输层
    -   网络层提供了一种不可靠的服务，它只是尽可能快把分组从源端口发送到目的窗口，但是并不能保证能毫发无损地准时送到。而传输层则利用TCP，UDP协议来保证传输。TCP采用超时重传，发送和接收端分组等机制来实现可靠传输。主要协议有TCP，UDP，TCP数据和UDP数据基本一致，唯一的区别是UDP传给IP的协议的信息单元称为UDP数据报。
-   应用层
    -   负责应用程序的具体需求，主要协议有FTP，TELNET，HTTP，HTML，STMP，POP，IMAP，DNS等

## 2.1 数据链路层
### 2.1.1 数据链路层-MAC地址
-   物理地址，arp
-   mac地址是网卡的物理地址，mac地址在出厂时都是唯一的。mac地址是数据在链路层传输时使用的地址。对于mac地址获取是通过发送arp包实现。
### 2.1.2 数据链路层-分组交换
-   分组交换是指将较大的数据分割为若干个较小的数据，然后依次发送。
-   使用分组交换的原因是不同的数据链路有各自的最大传输单元(MTU: Maximum Transmission Unit)。不同的数据链路就好比不同的运输渠道，一辆卡车(对应通信介质)的载重量为 5 吨。那么通过卡车运送 20 吨的货物就需要把这些货物分成四部分，每份重 5 吨。如果运输机的载重量是 30 吨，那么这些货物不需要分割，直接一架运输机就可以拉走。
-   以以太网(一种数据链路)为例，它的MTU是 1500 字节，也就是通过以太网传输的数据，必须分割为若干帧，每个帧的数据长度不超过 1500 字节。如果上层传来的数据超过这个长度，数据链路层需要分割后再发送。

## 2.1.3 数据链路层-以太网帧
### 2.1.3.1 以太网帧
-   在以太网链路上的数据包称作以太帧。
-   以太帧起始部分由前导码和帧开始符组成。
-   后面紧跟着一个以太网报头，以MAC地址说明目的地址和源地址。
-   帧的中部是该帧负载的包含其他协议报头的数据包(例如IP协议)。
-   以太帧由一个32位冗余校验码结尾。它用于检验数据传输是否出现损坏。
-   首部
    -   以太网首部包括目标mac地址，源mac地址和类型
        -   类型
            -   类型部分存储了上层协议的编号，比如上层是 IP 协议，则编号为 0800，ARP协议为0806。
    -   FCS
        -   FCS 表示帧校验序列(Frame Check Sequence)，用于判断帧是否在传输过程中有损坏(比如电子噪声干扰)。FCS 保存着发送帧除以某个多项式的余数，接收到的帧也做相同计算，如果得到的值与 FCS 相同则表示没有出错。

### 2.1.3.2 以太网(Ethernet II)每帧的数据构成:
-   目的Mac地址(`DMAC`)+源Mac地址(`SMAC`)+类型(`Type`)+数据(`Data`)+校验(`CRC`) =
-   6Bytes(48bit)`DMAC` + 6Bytes(48bit)`SMAC` + 2Bytes(16bit)`Type` + 1500Bytes`Data` + 4Bytes(24bit)`CRC`

### 2.1.3.3 MTU(Maximum Transmit Unit)
-   由于以太网传输的限制，每个以太网网数据帧的大小都是落在在区间`[64Bytes,1518Bytes]`中的，不在区间内的一般会被视为错误的数据帧，以太网转发设备直接丢弃。而根据以太网每帧的数据构成，除去固定的部分，留给上层协议的只有`Data`域的1500Bytes，我们将它称为MTU

![以太网帧](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7QHP3q5XNIXHhFldtX%2F-M7QZf3MHOjRcIkejwZ0%2Fimage.png?alt=media&token=e13b4032-b858-4eba-8fd4-f5d2a10344c4)

## 2.2 网络层
### 2.2.1 网络层-IP地址
-   IP地址是一种在网络层用于识别通信对端信息的地址。
-   它有别于数据链路层中的MAC地址，后者用于标识同一链路下不同的计算机
-   IP地址由两部分组成：**网络标识和主机标识**
    -   网络标识用于区分不同的网段，相同段内的主机必须拥有相同的网络表示，不同段内的主机不能拥有相同的网络标识。
    -   主机标识用于区分同一网段下不同的主机，它不能在同一网段内重复出现。
### 2.2.1.1 IP分类
#####  A类
-   A类IP地址是第一位为“0”的地址。A类IP地址的前8位是网络标识，用十进制标识的话0.0.0.0-127.0.0.0是A类IP地址的理论范围。另外我们还可以得知，A类IP地址最多只有128个(实际上是126个，下文不赘述)，每个网段内主机上限为2的24次方，也就是16，777，214个
##### B类IP地址
-   B类IP地址是前两位为“10“的地址。B类IP地址的前16位是网络标识，用十进制标识的话128.0.0.0-191.255.0.0是B类IP地址的范围。B类IP地址的主机标记长度为16位，因此一个网段内可容纳主机地址上限为65534个
##### C类IP地址
-   C类IP地址是前三位为“110”的地址。C类IP地址的前24位是网络标识，用十进制标识的话192.0.0.0-223.255.255.0是C类IP地址的范围。C类地址的后8位是主机标识，共容纳254个主机地址。
##### D类IP地址
-   D类IP地址是前四位为“1110”的地址。D类IP地址的网络标识长32位，没有主机标识，因此常用于多播

### 2.2.1.2 分片与重组
-   为什么要进行分片？
    -   如果要发送的数据超过以太网的MTU（默认1500字节），需要将数据进行拆分成多个片。拆开的分别独立寻找路径发送，需要强调的是：只有第一个分片，包含了传输层的首部。
-   如何重组？
    -   为了减少路由压力，规定重组只在最终目的主机进行。依靠IP首部中的16位标识和片偏移，实现重组。只有同属于一个包的片才具有相同的16位标识。
### 2.2.1.3 IP报文

![IP报文](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7QHP3q5XNIXHhFldtX%2F-M7QxRWNmmQAhCnR1aDh%2Fimage.png?alt=media&token=9bb424f4-18c4-4463-ac9a-98d265b2a310)


-   **IP报文**
    -   版本（Version）：
        -   由四位bit构成，表示IP的版本信息，如IPv4的版本号为4
    -   首部长度：
        -   表示IP首部的字节长度，如果没有可选字段，则首部长度为20字节
    -   区分服务：
        -   表示服务质量，如延时，吞吐量等
    -   总长度(Total Length)：
        -   表示IP首部与数据部分总的字节数，该段长16比特，所以IP包的最大长度为65535字节(2^16)。虽然不同数据链路的MTU不同，但是IP协议屏蔽了这些区别，通过自己实现的数据分片功能，从上层的角度来看，IP协议总是能够以65535为最大包长进行传输。
    -   标识（ID：Identification）：
        -   用于分片重组。属于同一个分片的帧的ID相同。但即使ID相同，如果目标地址、源地址、上层协议中有任何一个不同，都被认为不属于同一个分片。
    -   标志（Flags）：
        -   由于分片重组，由三个比特构成。
            -   第一个比特未使用，目前必须是0。
            -   第二个比特表示是否进行分片，0表示可以分片，1表示不能分片。在路径MTU发现技术中就用到了这个位。
            -   第三个比特表示在分片时，是否表示最后一个包。1表示不是最后一个包，0表示分配中最后一个包。
    -   片偏移（FO: Fragment Offset）：
        -   由13比特组成，表示被分片的段相对于原始数据的位置。它可以表示8192(2^13)个位置，单位为8字节，所以最大可以表示8 x 8192 = 65536字节的偏移量。
    -   生存时间（TTL: Time To Live）：
        -   表示包可以经过多少个路由器的中转。每经过一个路由器，TTL减1。这样可以避免前文提到的无限传递包的问题。
        - 占用8位二进制位，它指定了数据报可以在网络中传输的最长时间。实际应用中把生存时间字段设置成了数据报可以经过的最大路由器数。TTL的初始值由源主机设置（通常为32、64、128或256），一旦经过一个处理它的路由器，它的值就减1。当该字段为0时，数据报就丢弃，并发送ICMP报文通知源主机，因此可以防止进入一个循环回路时，数据报无休止地传输下去。
    -   协议：
        -   表示IP协议的上层协议使用了哪个协议。比如TCP协议的编号为6，UDP编号为17.
        - 目标端根据协议标识就可以把收到的IP数据报送到TCP或UDP等处理此报文的上层协议了。
    -   首部校验和：
        -   用于检查IP首部是否损坏
    -   可选项：
        -   仅在试验或诊断时用，可以没有。如果有，需要配合填充（Padding）占满32比特。

### 2.2.1.4 IP协议
-   ARP（Address Resolution Protocol）地址解析协议
-   DNS 解析

#### 2.2.1.4.1 ARP

ARP（Address Resolution Protocol，地址解析协议）是一种网络层协议，用于在局域网（LAN）中将IP地址解析为硬件地址（MAC地址）。ARP是IPv4的一个重要组成部分，用于在网络中确定与给定IP地址对应的物理设备的MAC地址。

ARP的工作原理

1. **ARP请求**：
   - 当一台主机需要与另一台主机通信时，它首先检查自己的ARP缓存表中是否有对方主机的MAC地址。
   - 如果找不到，它会发送一个广播帧到网络中的所有设备，询问谁拥有特定的IP地址。
   - 广播帧包含源主机的IP地址和MAC地址，以及目标IP地址。

2. **ARP响应**：
   - 网络中拥有该IP地址的设备会响应这个ARP请求，发送一个单播帧给请求方，包含它的MAC地址。
   - 响应帧包含源设备的IP地址和MAC地址，以及请求方所需的MAC地址。

3. **更新ARP缓存**：
   - 请求方主机接收到ARP响应后，会将目标设备的IP地址与MAC地址的对应关系存储在自己的ARP缓存表中。
   - 这样，在未来的通信中，就不需要再次发送ARP请求来查找MAC地址。

ARP缓存

- **ARP缓存**：每台主机都会维护一个ARP缓存表，用于存储最近解析过的IP地址与MAC地址的对应关系。
- **缓存老化**：ARP缓存中的条目会随着时间逐渐老化并最终被清除，以防止缓存中存储无效的映射。

ARP欺骗

- **ARP欺骗**：ARP协议本身并不具备安全性，攻击者可以通过伪造ARP响应来欺骗其他主机，从而将流量重定向到恶意设备。
- **防范措施**：为了防止ARP欺骗，可以使用静态ARP条目、ARP缓存验证机制（如DHCP Snooping和Dynamic ARP Inspection）等技术来提高网络的安全性。

ARP在IPv6中的替代方案

- **NDP（Neighbor Discovery Protocol）**：IPv6使用NDP作为ARP的替代方案，NDP不仅支持地址解析，还提供了邻居发现、路由器发现等其他功能。

总结

ARP是IPv4中用于地址解析的重要协议，它使得主机能够在不知道目标设备MAC地址的情况下发起通信。通过ARP，主机可以有效地在局域网内发现并与其他设备进行通信。然而，由于ARP缺乏内置的安全性，容易受到攻击，因此在现代网络中通常会结合其他安全措施来增强网络的安全性。
#### 2.2.1.4.2 DNS

DNS（Domain Name System，域名系统）是一种用于将人类可读的域名转换为计算机可识别的IP地址的服务。DNS是互联网基础设施的重要组成部分，它使得人们可以通过易于记忆的域名来访问网站和服务，而不是使用难以记忆的IP地址。

DNS的工作原理

1. **客户端请求**：
   - 当用户在浏览器中输入一个网址（如 www.example.com ）时，客户端（通常是用户的计算机或移动设备）会向本地DNS解析器发送一个DNS查询请求。

2. **递归查询**：
   - 本地DNS解析器（通常是ISP提供的DNS服务器或配置的公共DNS服务器）尝试解析域名。
   - 如果本地DNS解析器无法解析，它会递归地向其他DNS服务器发送查询请求，直到找到正确的IP地址。

3. **权威DNS服务器**：
   - DNS查询最终到达权威DNS服务器，这些服务器负责管理特定域名的DNS记录。
   - 权威DNS服务器会返回相应的A记录（IPv4地址）或AAAA记录（IPv6地址）。

4. **响应客户端**：
   - 一旦找到正确的IP地址，DNS解析器会将结果返回给客户端。
   - 客户端使用该IP地址与目标服务器建立连接。

5. **缓存**：
   - DNS解析器通常会缓存查询结果，这样在短时间内再次请求相同域名时可以更快地返回结果。

DNS记录类型

DNS支持多种类型的记录，其中包括：

- **A记录**：将域名映射到IPv4地址。
- **AAAA记录**：将域名映射到IPv6地址。
- **CNAME记录**：别名记录，将一个域名映射到另一个域名。
- **MX记录**：邮件交换记录，用于邮件路由。
- **NS记录**：名称服务器记录，指定哪个DNS服务器负责一个域名。
- **TXT记录**：文本记录，用于存储任意文本信息，例如SPF记录用于电子邮件认证。

DNS的安全性

- **DNSSEC**：DNS Security Extensions，用于保护DNS数据免受篡改，通过数字签名验证DNS记录的真实性。
- **DoH（DNS over HTTPS）**：通过HTTPS协议加密DNS查询，增加隐私保护和安全性。
- **DoT（DNS over TLS）**：使用TLS协议加密DNS查询，提供安全的DNS传输。

DNS的挑战

- **DNS缓存中毒**：攻击者通过伪造响应将恶意IP地址注入DNS缓存中。
- **DDoS攻击**：针对DNS服务器的大规模分布式拒绝服务攻击，导致正常用户无法访问服务。
- **DNS放大攻击**：利用DNS查询的放大效应进行拒绝服务攻击。

总结

DNS是互联网的基础服务之一，它通过将易于记忆的域名转换为IP地址，使得人们可以方便地访问互联网资源。DNS系统由多个层级组成，包括客户端、本地DNS解析器、递归DNS服务器和权威DNS服务器。通过DNS，用户可以高效、安全地访问互联网上的各种服务。

## 2.3 传输层
### 2.3.1 为什么需要传输层？
-   既然有了IP协议，能将数据发送到指定的主机为什么还要由传输层。原因有两点：
    -   IP协议提供的是不可靠的传输协议，它只是尽力将数据发送到目标主机，但是如果数据丢包，数据损坏，它都不能提供任何解决办法；
    -   IP协议只是将数据发送到了目标主机，但是应该由哪个应用程序来接受这个数据包呢？IP协议没有办法告诉我们。
    -   因此传输层的作用就是为了实现以上两点目的。
### 2.3.2 传输层协议 TCP / UDP
-   传输层协议有 TCP 协议和 UDP 协议。
    -   TCP 协议是面向有连接的协议，也就是说在使用 TCP 协议传输数据之前一定要在发送方和接收方之间建立连接。一般情况下建立连接需要三步，关闭连接需要四步。
#### 2.3.2.1 TCP
    -   TCP 协议是面向有连接的协议，还有数据重传、流量控制等功能，TCP 协议能够正确处理丢包问题，保证接收方能够收到数据，与此同时还能够有效利用网络带宽。然而 TCP 协议中定义了很多复杂的规范，因此效率不如 UDP 协议，不适合实时的视频和音频传输。
#### 2.3.2.2 UDP
    -   UDP 协议是面向无连接的协议，它只会把数据传递给接收端，但是不会关注接收端是否真的收到了数据。但是这种特性反而适合多播，实时的视频和音频传输。因为个别数据包的丢失并不会影响视频和音频的整体效果。
### 2.3.3 传输层新增端口号
#### 2.3.3.1 唯一标识通信
-   IP 协议中的两大关键要素是源 IP 地址和目标 IP 地址。而刚刚我们说过，传输层的主要作用是实现应用程序之间的通信。
-   因此传输层的协议中新增了两个要素：源端口号，目标端口号。再加上IP首部中的协议号，通过这五个信息，可以唯一识别一个通信。
-   用一句话来概括就是：“源 IP 地址，目标 IP 地址，源端口号，目标端口号和协议号”这五个信息只要有一个不同，都被认为是不同的通信。

源地址和目的地址的字段（32位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。
源端口和目的端口的字段（16位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。

#### 2.3.3.2 新增端口号作用
- 用于区分同一台主机中正在通信的不同应用程序，因此也被称为程序地址。不同的端口用于区分同一台主机上不同的应用程序。假设你打开了两个浏览器，浏览器 A 发出的请求不会被浏览器 B 接收，这就是因为 A 和 B 具有不同的端口。
#### 2.3.3.3 知名/动态端口号
-   分为两种：
        -   1. 知名端口号：这种端口号是固定的，用于服务器程序，使用对应协议的程序就将端口号设为对应的数字。比如DNS的端口号就是53.HTTP 80，FTP20，21，SSH23，SMTP25，
        -   2. 动态端口号：这种端口号是不固定的，用于客户端程序，客户端程序对端口号要求不高，只要该端口号在本机中唯一就行。

## 2.4 应用层

### 2.4.2 HTTPS协议
https经过了SSL（Secure Socket Layer，安全套接字层）或TLS（Transport Layer Security，传输层安全）的封装。单从这两个协议就可以知道，https安全的，而http是不安全的。
### 2.4.3 FTP协议
FTP（File Transfer Protocol）文件传输协议，在TCP/IP协议族中属于应用层协议运行于TCP协议之上是一种可靠的传输协议，主要功能用于实现用户间文件分发共享，以及网络管理者在进行设备版本升级、日志下载和配置保存等业务操作时，均会使用到FTP功能。
### 2.4.4 DNS协议
DNS是域名解析协议，假如我们知道了域名，但是不知道服务器的IP地址，就需要用到DNS协议。
### 2.4.5 DHCP协议
动态主机设置协议（DHCP）是一种使网络管理员能够集中管理和自动分配IP网络地址的通信协议。在IP网络中，每个连接Internet的设备都需要分配唯一的IP地址。DHCP使网络管理员能从中心结点监控和分配IP地址。当某台计算机移到网络中的其它位置时，能自动收到新的IP地址。


# 三、TCP与UDP的区别
### 3.1 TCP与UDP区别
-   Transmission Control Protocol 传输控制协议
-   **TCP基于有连接，UDP基于无连接**。
    -   有连接就是TCP在传输前先发送连接请求和应答包，确定双方能够正常传输后，才开始进行数据传输。无连接就是UDP在发送数据之前，并不考虑对方能否接受到，甚至目的地址可能都是无效；
-   **TCP能保证可靠传输，UDP不能保证可靠传输TCP**。
    -   所谓可靠就是TCP能保证把数据一定送到目的地址。为了实现可靠，TCP采用有连接的，超时重传，应答机制等。而UDP则没有这些，也不能保证数据一定能送到；
-   **TCP结构复杂，消耗资源多，建立过程较慢较复杂。UDP结构简单，消耗资源少，建立过程较快；**
-   **TCP基于流模式，UDP是数据报模式。**
    -   TCP把数据看成一连串无结构的字节流，没有边界，一段段传输构成了整个数据块。通过发送缓冲区和接受缓冲区来存储数据流。而UDP数据报模式，每一个数据报都是一个独立的对象，有着指定的大小。
-   **TCP连接只能是点到点，而UDP可以一对一，一对多或者多对多**。TCP只能是点到点原因很简单，因为TCP的传输前要先建立连接。因此，广播和多播只能采用UDP数据报的方式。
-   **TCP有确认，重传，拥赛控制机制，**UDP在没有建立连接或者对方已经退出的情况下任然会继续发送数据，导致通信流量的浪费。

|           TCP           |             UDP             |
| ----------------------- | --------------------------- |
| 面向连接                 | 无连接                      |
| 先建立连接，再发送        | 无需连接直接发送             |
| 特定顺序                 | 没有顺序                     |
| 速度慢                  | 速度快                      |
| 无连接头部20字节         | 头部8字节                    |
| 重量级，三次握手         | 轻量级，没有跟踪连接，消息排序 |
| 错误校验，错误恢复        | 错误检查，丢弃               |
| 发送确认                 | 没有确认                     |
| 握手协议SYN、SYNACK、ACK | 无握手协议                   |
| 可靠的，确保传输         | 不保证传输到目标             |
### 3.2 TCP/UDP用途区别
-   TCP：
    -   用于实现可靠传输的情况，文件非常重要，对网络拥堵有较高要求的情况。
    -   FTP / HTTP / HTTPS
-   UDP：
    -   1. 用于高速传输和实时性较高的场合（即时通信）。对于采用UDP的实事视频通信，如果出现丢包也只会出现短暂卡顿，但是如果采用TCP丢包后需要重发，会导致很长时间的卡顿。
    -   2. 包总量较少的通信（DNS），客户端较多
    -   3. 广播通信

‌
## 3.3 UDP首部
### 3.3.1 UDP首部图
![UDP首部](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7RBLjl-ZRtxDLHXqoQ%2F-M7RwZ_xqzV1HExsPEdM%2Fimage.png?alt=media&token=4d0acc45-ce40-484b-a4ae-3a70d06f00de)

### 3.3.2 UDP首部内容
头部只有 8 个字节（ 64 位）
#### 源端口号：
- 表示发送端端口号，不需要时设为0（2字节16位）
####  目标端口号：
- 表示接收端端口号（2字节16位）
#### 包长度：
- 表示整个UDP包的长度（2字节16位）
#### 校验和：
- 为了提供可靠的UDP首部和数据而设计，只要源IP地址，目标IP地址，源端口号，目标端口号，协议号有一个发生了篡改校验和都会不正确。（2字节16位）


## 3.4 TCP首部
### 3.4.1 TCP首部图
![TCP首部](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7RBLjl-ZRtxDLHXqoQ%2F-M7Sjt1_CNfAhNDFDuia%2Fimage.png?alt=media&token=5ea241e5-6f45-4cdc-9f54-242230b4e202)
### 3.4.2 TCP首部内容
-   源端口号：发送端端口号
-   目标端口号：接受端端口号
-   **<font color="blue">序列号</font >**：发送数据时，表示发送数据的位置，发送完一次数据后，序列号的值都等于原来的序列号加上数据的长度。<font color="blue">用来解决网络包乱序问题。</font>
-   **<font color="blue">确认应答号</font>**：用于接受端告诉发送端下次应该从哪个位置开始发送，表示前面的数据已经都收到了。<font color="blue">用来解决不丢包的问题。</font>
-   数据偏移：实际就是TCP首部长度
-   保留：一般设置为0，用于后续扩展
-   **<font color="blue">控制位</font >**：长度为8，从左到右分别是CWR，ECE，URG，ACK，PSH，RST，SYN，FIN
    + <font color="blue">ACK</font>：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 <font color="red">SYN</font> 包之外该位必须设置为 1 。
    + <font color="blue">RST</font>：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。
    + <font color="blue">SYC</font>：该位为 1 时，表示希望建立连，并在其「序列号」的字段进行序列号初始值的设定。
    + <font color="blue">FIN</font>：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换<font color="red"> FIN </font>位置为 1 的 TCP 段。
-   窗口大小：能够发送数据的最大值，为0时可以发送探测窗口
-   校验和：与UDP校验和作用相同
-   紧急指针：用于处理紧急情况
-   选项：其他控制设置

### 3.5 为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？
原因是 TCP 有`可变长的「选项」`字段，而 `UDP 头部`长度则是不会变化的，无需多一个字段去记录 UDP 的首部长度。
先说说 TCP 是如何计算负载数据长度：
```
TCP数据长度=IP总长度-IP首部长度-TCP首部长度
```
其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。
大家这时就奇怪了问：“ UDP 也是基于 IP 层的呀，那 UDP 的数据长度也可以通过这个公式计算呀？为何还要有「包长度」呢？”
这么一问，确实感觉 UDP 「包长度」是冗余的。
**因为为了网络设备硬件设计和处理方便，首部长度需要是 4字节的整数倍。**
如果去掉 UDP 「包长度」字段，那 UDP 首部长度就不是 4 字节的整数倍了，所以敖丙觉得这可能是为了补全 UDP 首部长度是 4 字节的整数倍，才补充了「包长度」字段。

# 四、TCP协议
### 4.1 TCP是如何确保可靠传输的？
-   为了保证可靠传输，TCP比UDP多了很多控制协议和算法。
    -   连接管理——3次握手和4次握手
    -   数据破坏——通过校验和
    -   丢包——应答与超时重发机制
    -   分片乱序——序列号
    -   窗口滑动——提高发送效率，对发送端和接收端流量进行控制
    -   加快通信速度——快速重发，三次收到重发消息进行重发
    -   流控制——避免网络流量浪费
    -   拥塞控制——慢启动算法，拥塞窗口

### 4.2 TCP中的确认应答机制 以及 多种机制来优化网络通信
-   在TCP中当发送端的数据达到接受主机时，接受主机端都会返回一个消息，告诉对方我已经收到了。这个消息叫**确认应答**。发送确认应答时，TCP首部中的ACK标志位设1。
-   TCP中的确认应答通过序列号和确认应答号来实现。如下图所示，主机A发送第一个包时序列号为1，数据长度为1000，那么主机B收到包后发送一个数据包给主机A，在该包中将TCP首部中的32位确认号设为1001.相当于告诉对方1001之前的我都收到了，下次从1001开始发。
-   **经受时延的确认应答**：为了降低确认应答包的数量，TCP提出了经受时延的确认应答。接受端在收到数据后并不立即发送一个应答数据包，而是等待一段时间，如果有新的数据被接受就更新应答号，如果有其他数据要发送就坐上该数据包的顺风车。在系统的内核中维持了一个定时器，一般是200ms如果定时器溢出，即使没有其他数据到达，也发送该应答数据包。
-   **Nagle算法**： 它主要在发送端起作用;TCP是基于流的传输协议，在Rlogin和Telnet传输中会出现只有一个字节数据的TCP数据包。而一个TCP数据包的首部加上IP首部就有40个字节，很显然发这样的数据包划不来。为了减少这样的数据包，有人提出了Nagle算法。
    -   Nagle算法简单讲就是，等待服务器应答包到达后，再发送下一个数据包。数据在发送端被缓存，如果缓存到达指定大小就将其发送，或者上一个数据的应答包到达，将缓存区一次性全部发送。
-   Nagle算法是从<span style="color:red;">发送端角度考虑减少了数据包的个数</span>，时延应答从<span style="color:red;">接收端角度考虑减少了数据包的个数</span>。

Nagle代码控制：
Nagle算法是TCP协议中用于优化网络传输效率的一种机制，它通过减少小数据包的发送次数来提高网络带宽的利用率。默认情况下，大多数TCP实现都会启用Nagle算法。但是，如果应用程序的实时性要求高于带宽利用率，或者网络环境不适合Nagle算法（例如，高延迟的卫星链接），你可能需要禁用Nagle算法。

在C语言中，可以通过`setsockopt`函数来控制Nagle算法的启用或禁用。以下是如何在C/C++中禁用Nagle算法的例子：

```c
#include <sys/socket.h>
#include <netinet/tcp.h>

void disable_nagle(int sockfd)
{
    int one = 1;
    if (setsockopt(sockfd, IPPROTO_TCP, TCP_NODELAY, &one, sizeof(one)) == -1) {
        perror("setsockopt");
        // Handle error
    }
}
```

上述代码定义了一个`disable_nagle`函数，它接受一个socket描述符作为参数。函数中，`setsockopt`函数被用来设置`TCP_NODELAY`选项，该选项告诉TCP层不要应用Nagle算法，而是立即发送数据，即使数据量很小。

如果你想要在Python中禁用Nagle算法，可以使用以下代码：

```python
import socket

def disable_nagle(sock):
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)

# 创建socket
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# 禁用Nagle算法
disable_nagle(sock)
# 进行连接和其他操作...
```

在某些情况下，你可能希望保留Nagle算法的某些特性，同时又能发送小数据包而不受算法的影响。这通常发生在需要高实时性的应用中，如游戏或实时音频/视频通信。在这种情况下，你可以考虑使用`TCP_CORK`选项，它允许你在发送一系列小数据包时先缓冲它们，然后一次性发送，而不是等待Nagle算法的阈值或超时。不过，这需要应用程序在发送完所有需要缓冲的数据后明确调用`flush`或关闭`TCP_CORK`选项。

请注意，`TCP_NODELAY`和`TCP_CORK`选项可能会影响应用程序的行为，因此在修改这些选项之前，应充分理解它们的作用和可能带来的影响。
## 4.3 TCP连接 断开 状态转换
### 4.3.1 三次握手四次挥手状态
![TCP_Status](https://cdn.jsdelivr.net/gh/aemonair/ImageHosting/images/20200513165040_TCPSTATUS.jpg)


### 4.3.2 三次握手( 建立连接 )

1. `SYN (Synchronize Sequence Numbers)`同步序列编号。
    是 TCP/IP 建立连接时使用的握手信号。
    在客户机和服务器之间建立 TCP 连接时，首先会发送的一个信号。
    客户端在接受到 SYN 消息时，就会在自己的段内生成一个随机值 X。
2. `SYN-ACK`：服务器收到 SYN 后，打开客户端连接，发送一个 `SYN-ACK` 作为答复。
    确认号设置为比接收到的序列号多一个，即 X + 1，服务器为数据包选择的序列号是另一个随机数 Y。
3. `ACK：(Acknowledge character)`, 确认字符，
    表示发来的数据已确认接收无误。
    最后，客户端将 ACK 发送给服务器。序列号被设置为所接收的确认值即 Y + 1。

>> sent - send的过去分词和过去式;

> `syn_sent`: syn package has been sent
> `syn_rcvd`: syn package has been received

-   客户端发送请求包，告诉服务器：“我想和你通信？”数据包中SYN位置为1，假设其序列号为x，客户端状态变成SYN_SENT；
-   服务器端接受到请求包后也发送一个请求包，告诉客户端：“现在可以建立连接”。数据包中SYN位置位1，假设其序列号为y，注意客户端序列号和服务器端序列号并没有关系，他们是由各自的内核按照一定的规则生成的。但是这个应答包的32位应答号，必须是x+1，之所以加1是因为客户端发过来的包SYN位被认为占一个数据。因此，告诉下一包从x+1开始发。发送后，服务器从监听状态变成SYN_RCVD状态。
-   客户端发送应答数据包，告诉服务器：“那我们开始发送数据吧”。数据包应答号为y+1。客户端变成ESTABLISHED状态，即可以传输状态。
>   服务器端接受到应答数据包后，变成ESTABLISHED状态。o第三次握手是可以携带数据的，前两次握手是不可以携带数据的，
 ![TCP](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeo9xBVAyPJ8iaWCC6sYS843fFol7gd3035Kibg3gPMSAZQLVibf9nwEblOUaX80hoOaRLVpaYCAI44w/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
### 4.3.3 发送数据
-   客户端发送一个一个字节的数据，因此序列号为x+1；
-   服务端发送一个应答包，应答号为x+2，告诉客户端下次从x+2开始发；
### 4.3.4 断开连接
![四次挥手](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeo9xBVAyPJ8iaWCC6sYS843KaMMu2mHfFLZNgiaREDZ5JicRYrlaiciayQjh9HDsacxIbMT0emGUpAX5w/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
-   客户端发送请求断开的数据包，告诉服务器：“数据传完了，我要断开了”。发送一个FIN包，序列号x+2。客户端转移到`FIN_WAIT_1`状态。
-   服务器端发送应答包，告诉客户端：“行，我知道了，你断开吧！”。应答号为x+3，服务器进入`CLOSE_WAIT`状态。客户端收到应答后，转移到`FIN_WAIT_2`状态。
-   服务器发送一个断开数据包，告诉客户端：“既然传完了，那我这边的开关也准备关了”。序列号为y+1，发送完后服务器进入`LAST_ACK`状态。
-   客户端发送一个应答包，告诉服务器：“好的，我知道你要断开了。”应答号为y+2。客户端进入`TIME_WAIT`状态。
    - 主动关闭连接的，才有 TIME_WAIT 状态
-   TIME_WAIT又称为2MSL等待状态，MSL是系统中定义的最大报文生存时间，任何TCP报文在网络中生存时间超过这个值就必须被丢弃。
-   等待MSL的原因是防止最后一个ACK丢失后可以进行重发，如果ACK丢失后，服务器会重发FIN。
-   当客户端收到从服务端发送的 FIN 消息时，客户端就会由 FIN_WAIT_2 状态变为 TIME_WAIT 状态。
-   处于 TIME_WAIT 状态的客户端允许重新发送 ACK 到服务器为了防止信息丢失。
-   客户端在 TIME_WAIT 状态下花费的时间取决于它的实现，在等待一段时间后，连接关闭，客户端上所有的资源（包括端口号和缓冲区数据）都被释放。
### 4.3.5 MSL
- Maximum Segment Lifetime <font color="red">报文最大生存时间</font> 它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。
- 如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 Fin 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方，<font color="blue"> 一来一去正好 2 个 MSL</font>。
- 2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。

-   2MSL
    -   连接双方任何一方调用`close()`后，连接的两个传输方向都关闭，不能再发送数据了。如果一方调用`shutdown()`则连接处于半关闭状态，仍可接收对方发来的数据。
    -   如果出现半关闭，例如客户->服务器方向关闭。则服务器还可以发，客户端还可以收。
    -   协议规定主动关闭一方，进入`FIN_WAIT_2`->`TIME_WAIT`，必须等待2MSL（MSL为最大报文段生存时间，LWIP为1分钟，windows为2分钟）时间然后才进入`CLOSED`，删除TCP控制块。在2MSL等待时间内迟到的报文段将被抛弃。
    -   如果我们在客户端关闭一个连接然后又立刻建立连接（使用同一端口号），2MSL时间内之前连接的端口号不能使用，即使调用`bind`函数也将返回-1（绑定失败），内核将自动分配一个新的端口号使用。通常情况下这个我们并不关心，因为客户端的端口号我们并不关心，只要能用就可以。但是如果是服务器就不一样了，服务器的端口一般是固定的，客户端必须知道服务器的端口号才能建立连接，所以如果服务器端主动断开连接时，就需要注意，或者做一些处理：不让它等待2MSL后才可以使用，具体做法：使能`SO_REUSEPORT`(允许重用本地地址)，可以通过调用`setsockopt`函数来使能。

## 4.4 2MSL
### 4.4.1  2MSL等待的原因：
-   报文段有生存时间，当连接关闭时，有可能收到迟到的报文段。这时，若立马就建立新的连接（同一端口），那么新的连接就会接收迟到的报文，误以为是发给自己的。另一个原因是可靠的实现全双工连接的终止。
-   在`FIN_WAIT_2`状态我们已经发出了`FIN`，并且另一端也已对它进行确认。除非我们在实行半关闭，否则将等待另一端的应用层意识到它已收到一个文件结束符说明，并向我们发一个FIN来关闭另一方向的连接。只有当另一端的进程完成这个关闭，我们这端才会从`FIN_WAIT_2`状态进入`TIME_WAIT`状态。这意味着我们这端可能永远保持这个状态(`FIN_WAIT_2`,如果对方不发送FIN包)。另一端也将处于`CLOSE_WAIT`状态，并一直保持这个状态直到应用层决定进行关闭（调用`close`然后进入`LAST_ACK`）。

### 4.4.2 为什么需要 TIME_WAIT 状态？
主动发起关闭连接的一方，才会有 TIME-WAIT 状态。
需要 TIME-WAIT 状态，主要是两个原因：

- 防止具有相同「四元组」的「旧」数据包被收到；
- 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；

#### 原因一：防止旧连接的数据包
假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？
有相同端口的 TCP 连接被复用后，被延迟的 SEQ = 301 抵达了客户端，那么客户端是有可能正常接收这个过期的报文，这就会产生数据错乱等严重的问题。
2MSL 这个时间，足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。
#### 原因二：保证连接正确关闭
TIME-WAIT 作用是等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。
如上图红色框框客户端四次挥手的最后一个 ACK 报文如果在网络中被丢失了，此时如果客户端 TIME-WAIT 过短或没有，则就直接进入了 CLOSE 状态了，那么服务端则会一直处在 LASE-ACK 状态。
当客户端发起建立连接的 SYN 请求报文后，服务端会发送 RST 报文给客户端，连接建立的过程就会被终止。

如果 TIME-WAIT 等待足够长的情况就会遇到两种情况：
- 服务端正常收到四次挥手的最后一个 ACK 报文，则服务端正常关闭连接。
- 服务端没有收到四次挥手的最后一个 ACK 报文时，则会重发 FIN 关闭连接报文并等待新的 ACK 报文。
所以客户端在 TIME-WAIT 状态等待 2MSL 时间后，就可以保证双方的连接都可以正常的关闭。

### 4.2.3 TIME_WAIT 过多有什么危害？
如果服务器有处于 TIME-WAIT 状态的 TCP，则说明是由服务器方主动发起的断开请求。

过多的 TIME-WAIT 状态主要的危害有两种：
第一是内存资源占用；
第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口；
第二个危害是会造成严重的后果的，要知道，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过如下参数设置指定
net.ipv4.ip_local_port_range
如果服务端 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。

## 4.5 为什么是3次和4次？
### 4.5.1 为什么是3次
#### 4.5.1.1 举例
-   可能你会认为第3次好像是多余的。是因为信道是不可靠的，可能存在延时或者丢包，而三次是满足可靠传输的最小次数。
-   举例说明：如果只有两次，假设主机A发送的第一个请求包延时，主机A在等待一段时间后重新发送一个请求包，完成数据连接并断开。但是这个时候上次的发的请求包才到达主机B，这时主机B认为是又一次连接，因此发送一个请求包给A，但是Ａ并没有发送新的请求因此会丢失该数据包。最后，B就一直等待A发送数据，浪费了资源。
-   除此之外，我个人认为3次握手更加安全，加大了攻击的难度。如果只有两次，一个发送一个应答，那么攻击着可以采用IP欺骗，发动SYN洪水攻击，并且服务端还都是ESTABLISHED状态。如何防御？难度更大了。对于三次握手的可以限制半连接的数量来达到一个防御的作用。

#### 4.5.1.2 原因
> 三次握手才可以阻止历史重复连接的初始化（主要原因）
> 三次握手才可以同步双方的初始序列号
> 三次握手才可以避免资源浪费

##### 4.5.1.2.1 原因一：避免历史连接
> The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.
> 三次握手的首要原因是为了**防止旧的重复连接初始化造成混乱**。

客户端连续发送多次 SYN 建立连接的报文，在网络拥堵等情况下：
一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端；
那么此时服务端就会回一个 SYN + ACK 报文给客户端；
客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 `RST 报文`给服务端，表示中止这一次连接。

如果是`两次`握手连接，就`不能判断`当前连接是否是历史连接，`三次握手`则可以在客户端（发送方）准备发送第三次报文时，客户端因有`足够的上下文来判断`当前连接是否是历史连接：

- 如果是历史连接（序列号过期或超时），则第三次握手发送的报文是 RST 报文，以此中止历史连接；
- 如果不是历史连接，则第三次发送的报文是 ACK 报文，通信双方就会成功建立连接；

所以， TCP 使用三次握手建立连接的最主要原因是**防止历史连接初始化了连接**。

##### 4.5.1.2.2 原因二：同步双方初始序列号

TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

  - 接收方可以去除重复的数据；
  - 接收方可以根据数据包的序列号按序接收；
  - 可以标识发送出去的数据包中， 哪些是已经被对方收到的；

序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样**一来一回，才能确保双方的初始序列号能被可靠的同步**。

##### 4.5.1.2.3 原因三：避免资源浪费
    - 如果客户端的 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。

#### 4.5.1.3 小结

TCP 建立连接时，通过三次握手能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号。序列号能够保证数据包不重复、不丢弃和按序传输。

不使用「两次握手」和「四次握手」的原因：
「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

### 4.5.2 为什么是4次
-   TCP通信是一种全双工的通信，可以进行半关闭（与半打开区别：半打开是连接后的客户端和服务端有一端异常关闭了），所谓半关闭是指可以只关闭从A到B的方向，而B到A的方向还可以继续传输。因此，在客户端和服务器端分别进行关闭。
- 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。
- 服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。

## 4.6 SYN 攻击
### 4.6.1 SYN 攻击 概念
攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务。
### 4.6.2 SYN 攻击 避免
#### 4.6.2.1 避免 SYN 攻击方式一
修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理。
- 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数：
`net.core.netdev_max_backlog`
- SYN_RCVD 状态连接的最大个数：
`net.ipv4.tcp_max_syn_backlog`
- 超出处理能时，对新的 SYN 直接回 RST，丢弃连接：
`net.ipv4.tcp_abort_on_overflow`
#### 4.6.2.2 避免 SYN 攻击方式二
正常流程：
当服务端接收到客户端的 SYN 报文时，会将其加入到内核的「 SYN 队列」；
接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；
服务端接收到 ACK 报文后，从「 SYN 队列」移除放入到「 Accept 队列」；
应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。

如果不断受到 SYN 攻击，就会导致「 SYN 队列」被占满。
tcp_syncookies 的方式可以应对 SYN 攻击的方法：
`net.ipv4.tcp_syncookies = 1`

当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」；
计算出一个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，
服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列」。
最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。
## 4.7 “粘包”
### 4.7.1 “粘包”是什么？
“粘包”通常是指在网络通信中出现的一种现象，特别是在TCP协议的流式传输中。在TCP通信中，数据是以字节流的形式发送的，而不是以消息或报文的形式。这意味着发送端发送的数据包可能会在接收端合并成一个更大的数据块，或者相反，一个大的数据包可能会被分割成多个较小的数据包发送。这种情况被称为“粘包”或“拆包”。

具体来说，“粘包”现象包括以下几种情况：

1. **数据包合并**：发送方发送的两个或多个数据包在接收方被合并成一个数据包。
2. **数据包分割**：发送方发送的一个数据包在接收方被分割成两个或多个数据包。

这两种情况都会导致接收端难以正确解析接收到的数据，因为接收端需要知道每个独立的消息的边界在哪里。

### 4.7.2 如何解决粘包问题？

要解决粘包问题，常见的方法包括：

1. **固定长度消息**：发送固定长度的消息，这样接收端可以根据固定的长度来区分不同的消息。
2. **消息头携带长度信息**：在每个消息的头部附加一个字段，用来指示消息的总长度。接收端读取到消息头后，就可以知道接下来需要接收多少字节才能构成一个完整的消息。
3. **消息之间填充分隔符**：在消息之间填充特定的分隔符（如换行符或其他特殊字符），接收端可以通过检测这些分隔符来识别消息的边界。
4. **使用自定义协议**：设计一个简单的协议，使得发送端和接收端都能够按照相同的规则来处理消息。

### 4.7.3 粘包示例

假设发送端发送了两个消息：“Hello” 和 “World”，如果这两个消息粘在一起成为“HelloWorld”，接收端就需要一种机制来区分这两个消息。

- **固定长度消息**：如果约定每个消息长度为5个字符，那么接收端可以直接读取前5个字符作为第一个消息，接着读取后面的5个字符作为第二个消息。
- **消息头携带长度信息**：如果第一个消息是“Hello”，可以在前面加上长度信息，比如“5:Hello”，接收端读取到“5”就知道接下来的5个字符构成一个消息。
- **消息之间填充分隔符**：如果约定使用“|”作为分隔符，发送端发送“Hello|World”，接收端读取到“|”就认为是一个消息的结束。

通过上述方法，可以有效地避免粘包问题，保证数据的正确传输和解析。

# 五、TCP滑动窗口 拥塞控制
### 5.1 TCP窗口
-   窗口是TCP中为了解决应答机制等待时间过长而引入的方法，
-   解决问题：
    -   如果没有窗口，则TCP每发送一次数据就必须等待应答，收到应答后继续发送，如果没有收到则等待一段时间后重发，如果很长时间都无法收到应答则判断为网络断开。
-   **解决方案:**
    -   引入窗口后，发送端只要在窗口内，便不用每次都等待ACK才发送下一个报文段，可以在发送窗口内一次连续发送几个报文段而无需等待ACK
    -   窗口的大小指无需等待应答可以连续发送多个数据包。
### 5.2 Windows Scaling 窗口缩放
-   由于表示Window Size的字段只有16位，因此按照协议，能表示的最大窗口大小是`2^16-1=65535Bytes`(64Kb)，因此TCP的选项字段中包含了窗口扩大因子(`WS`)分别用`option-kind`、`option-length`、`option-data`来表示，这个参数可带可不带，只有在双方都支持的情况下，才会生效。
-   如双方的`WS`都是256，而后我们ACK `Window size value`是5，那么此时就可以表示我们的接收窗口是1280Bytes(`5*256=1280`)。
### 5.3 发送窗口
-   （1）已经发送并且对端确认 （Sent/ACKed）---------------发送窗外 缓冲区外
-   （2）已经发送但未收到确认数据（Sent/UnACKed）-----------发送窗内 缓冲区内
-   （3）允许发送但尚未发送的数据（Unsent/Inside）-------------发送窗内 缓冲区内
-   （4）未发送暂不允许 （Unsent/Outside）-----------发送窗外 缓冲区内
-   2，3两部分为发送窗口
### 5.4 接收窗口
-   （1）已接收
-   （2）未接收准备接收
-   （3）未接收并未准备接收
-   2为接收窗口
-   （由于ACK直接由TCP协议栈回复，默认无应用延迟，不存在“已接收未回复ACK”）。

![滑动窗口](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7VebxkOb2wrp7LRc_u%2F-M7VorKsql1cU48Nu-8c%2Fimage.png?alt=media&token=363b422b-9580-4d09-9885-1d79e4611f43)

## 5.5 滑动窗口
### 5.5.1 滑动窗口 （累计ACK
-   TCP并不是每一个报文段都会回复ACK的，可能会对两个报文段发送一个ACK，也可能会对多个报文段发送1个ACK【累计ACK】。
-   比如说发送方有1/2/3共3个报文段，先发送了2,3 两个报文段，但是接收方期望收到1报文段，这个时候2,3报文段就只能放在缓存中等待报文1的空洞被填上，
    -   如果报文1，一直不来，报文2/3也将被丢弃，
    -   如果报文1来了，那么会发送一个ACK对这3个报文进行一次确认。
### 5.5.2  举一个例子来说明一下滑动窗口的原理：
1.  假设32~45 这些数据，是上层Application发送给TCP的，TCP将其分成四个Segment来发往internet
2.  `<seg1 32~34 >`、`<seg2 35~36>` 、`<seg3 37~41>`、`<seg4 42~45>` 这四个片段，依次发送出去，此时假设接收端之接收到了seg1 seg2 seg4
3.  此时接收端的行为是回复一个ACK包说明已经接收到了32~36的数据，并将seg4进行缓存（保证顺序，产生一个保存seg3 的hole）
4.  发送端收到ACK之后，就会将32~36的数据包从发送并没有确认切到发送已经确认，提出窗口，这个时候窗口向右移动
5.  假设接收端通告的Window Size仍然不变，此时窗口右移，产生一些新的空位，这些是接收端允许发送的范畴
6.  对于丢失的seg3，如果超过一定时间，TCP就会重新传送（重传机制），重传成功会seg3 seg4一块被确认，不成功，seg4也将被丢弃
### 5.5.3 滑动窗口图示
![窗口](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7VebxkOb2wrp7LRc_u%2F-M7VpvC6yIDQEosMyYIr%2Fimage.png?alt=media&token=815e738b-ce3b-4be7-942a-e8b3f04e19fb)



![窗口滑动](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7VebxkOb2wrp7LRc_u%2F-M7Vq1GmpAuUGLu4hyt1%2Fimage.png?alt=media&token=c055988d-db58-4cee-b80c-4f36a5873133)

-   -   发送端窗口，根据应答包的确认号确定窗口的位置，根据应答包中窗口的大小确定窗口的大小，窗口是从左向右逐渐滑动。
    -   **窗口合拢：**由左端边缘向右靠近，称为窗口合拢，在接受到数据后发生。
    -   **窗口张开：**右右端向右移动，称为窗口打开，在处理完数据后发生。
-   滑动窗口动态调整
    -   接收端可以根据自己的状况通告窗口大小，从而控制发送端的接收，进行流量控制
    -   如果接收端发送的应答包中窗口大小为0，则客户端会等待一段时间后发送探测包，重新确认窗口的大小。
    -   接受端如果处理完了数据也会重新发送应答包，通知发送端。防止死锁的发生。
    -   客户端不断快速发送数据，服务器接收相对较慢，看下实验的结果
        a. 包175，发送ACK携带WIN = 384，告知客户端，现在只能接收384个字节
        b. 包176，客户端果真只发送了384个字节，Wireshark也智能宣告TCP Window Full
        c. 包177，服务器回复一个ACK，并通告窗口为0，说明接收方已经收到所有数据，并保存到缓冲区，但是这个时候应用程序并没有接收这些数据，导致缓冲区没有更多的空间，故通告窗口为0, 这也就是所谓的零窗口，零窗口期间，发送方停止发送数据
        d. 客户端察觉到窗口为0，则不再发送数据给接收方
        e. 包178，接收方发送一个窗口通告，告知发送方已经有接收数据的能力了，可以发送数据包了
        f. 包179，收到窗口通告之后，就发送缓冲区内的数据了.

![动态调整](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7VebxkOb2wrp7LRc_u%2F-M7VrvROg2N6pQEz4FQe%2Fimage.png?alt=media&token=ee42f97c-b28a-43da-999c-d1388780b216)



-   -   引入窗口后，TCP的应答包如果部分丢失，无需重传，由后面的应答包保证。TCP为了提高效率，采用延时再确认应答，和选择性确认应答，即收到数据包后不立即发送应答包，而是等待收到下一个或多个包后发一个应答。

# 六、 超时和重传
### 6.0 超时和重传
-   TCP是可靠的传输协议，意味着必须按序，无差错的传送数据和目的端。
-   通过校验和，确认应答，重传来保证。重传机制分为两种：超时重传和快速重传。
### 6.1 超时重传（RTO）
-   当一个包被发送后，就开启一个定时器，如果定时时间到了，还未收到能确认该发送包的应答包，就重传一份数据。注意收到的应答包可能是该包也可能是后面包的，但是只要能确认该包被收到就行。另外如果，是因为网络延时造成重传，则接受端收到重复数据包后丢弃该包。
### 6.2 快速重传
-   当如果发送端收到一个包的三次应答包后，立即重传，比超时重传更高效。
### 6.3 重传图示
![快速重传](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7VebxkOb2wrp7LRc_u%2F-M7W0Kw59OzrHOdTLSBF%2Fimage.png?alt=media&token=b93f1290-f35b-40ec-ae93-d0a742496ad8)


# 七、拥塞控制

### 7.1 拥塞控制
-   流量是根据发送方和接受方的缓冲区大小来确定的，保证数据处理不出现拥堵，具体实现方法是窗口滑动。
而拥塞机制是考虑到网络中的拥堵，比如路由器要处理的数据过多，导致缓冲区溢出而丢包。而拥塞处理就是来解决这种情况，避免网络出现过载的现象。

拥塞控制是指在网络中控制数据源发送速率的机制，以避免网络拥塞
拥塞处理是指在网络出现拥塞时，如何处理和应对拥塞的行为

拥塞控制（Congestion Control）是计算机网络中用于防止网络资源过度使用，尤其是防止网络带宽和节点缓存空间耗尽的技术。网络拥塞会导致数据包丢失、延迟增加以及服务质量下降。拥塞控制的目标是在网络达到其容量极限之前，通过调整数据传输率来减少数据注入网络的数量，从而保持网络的高效和稳定运行。

拥塞避免（Congestion Avoidance）是拥塞控制策略的一部分，它侧重于在网络尚未达到严重拥塞状态时就开始采取行动，防止网络拥塞的发生。拥塞避免算法试图在拥塞窗口（cwnd）达到某个阈值（ssthresh）之前平滑地减小发送速率，而不是等到网络已经拥塞才做出反应。

TCP（Transmission Control Protocol）的拥塞避免算法工作原理如下：

1. **慢启动（Slow Start）**：在连接开始或重新启动时，发送端会缓慢地增加其拥塞窗口大小，通常每次收到一个确认就增加一个MSS（最大报文段大小）。拥塞窗口从1开始，每收到一个ACK就加倍，直到达到ssthresh阈值。

2. **拥塞避免（Congestion Avoidance）**：一旦cwnd达到ssthresh阈值，就进入拥塞避免阶段。在这个阶段，cwnd的增长不再是指数式的，而是线性的。每当收到一个ACK，cwnd只增加一个MSS，而不是翻倍。这样做的目的是更精细地控制cwnd的大小，防止突然的流量激增导致网络拥塞。

3. **快速重传（Fast Retransmit）**：如果发送端检测到数据包丢失（通常通过重复的ACKs识别），它不会等待重传计时器到期，而是立即重传丢失的数据包。

4. **快速恢复（Fast Recovery）**：当检测到数据包丢失时，cwnd并不会像慢启动那样重置为1，而是降低到ssthresh的一半，并且开始快速恢复，以尽快恢复正常传输速率。

通过这些机制，TCP能够有效地响应网络状况的变化，避免网络拥塞，同时保持较高的传输效率。不同的拥塞控制算法（如Reno、New Reno、Vegas、CUBIC等）可能对这些基本机制有不同的实现细节和优化。

### 7.2 判定拥塞出现的条件
    -   网络中出现分组丢失（发生超时或收到重复确认）
在TCP（Transmission Control Protocol）中，判定网络拥塞出现的条件主要是基于以下几个关键指标和事件：

1. **超时重传（Timeout Retransmission）**：
   当发送端发出的数据包在一定时间内没有收到接收端的确认（ACK），则认为该数据包可能在网络中丢失，这可能是网络拥塞的结果。TCP会有超时重传机制，如果超时重传次数过多，可以表明网络拥塞较为严重。

2. **重复确认（Duplicate ACKs）**：
   当接收端收到乱序的数据包时，它会连续发送多次对于最后一个正确顺序数据包的确认，这被称为重复确认。三次重复确认（Three Duplicate ACKs）被TCP视为网络拥塞的早期迹象，因为数据包的乱序往往意味着网络中有数据包丢失或延迟，这通常是由网络拥塞引起的。

3. **拥塞窗口（Congestion Window, cwnd）的动态变化**：
   当网络处于非拥塞状态时，cwnd会逐渐增大，允许发送更多的数据。如果网络出现拥塞，cwnd会根据拥塞控制算法（如慢启动、拥塞避免、快速重传和快速恢复）进行调整，减小数据发送速率，以缓解网络压力。

4. **慢开始门限（Slow Start Threshold, ssthresh）的调整**：
   当检测到网络拥塞（如超时重传或接收到三次重复确认），ssthresh会被调整（通常是减半），并且cwnd被重置到较小的值，然后重新开始慢开始过程。这有助于避免在恢复时突然注入过多的流量到网络中，从而进一步加剧拥塞。

5. **往返时间（Round-Trip Time, RTT）的增加**：
   如果RTT突然增加，这可能表明数据包在网络中遇到更长的排队时间，这也是网络拥塞的一个迹象。TCP可能会监测RTT的变化，作为调整cwnd的辅助信息。

6. **资源利用率**：
   虽然TCP不直接监测网络中的资源利用率（如链路带宽、缓冲区大小），但上述条件间接反映了网络资源的利用情况。当资源利用率接近或超过网络的承载能力时，网络拥塞便可能发生。

通过这些条件和事件，TCP能够动态调整其拥塞控制机制，以适应不断变化的网络状况，防止或减轻网络拥塞，保证数据传输的可靠性和效率。
### 7.3.0  拥塞避免算法
拥塞避免算法（Congestion Avoidance Algorithm）是TCP（Transmission Control Protocol）拥塞控制机制中的一个重要组成部分，它设计用于在网络拥塞发生前平滑地减小发送速率，防止网络资源（如带宽和缓冲区）被过度使用，从而避免严重的网络拥塞和数据包丢失。

在 TCP（传输控制协议）中，最常用的拥塞避免算法是 "慢启动" 和 "拥塞避免"。它们都通过动态调整所谓的 "拥塞窗口"（即一次可以发送而无需确认的数据包数量）来工作。当网络表现良好时，这个窗口会逐渐增大，允许更快的数据传输。但当出现数据包丢失时，这个窗口就会减小，以减少网络压力。
- 拥塞避免算法中用到了**慢启动**，**快速重传**，**快速恢复**。
- 拥塞避免算法需要维持两个变量：**拥塞窗口**和**慢启动阀值**。
### 7.3.1 慢启动算法（工作过程如下图所示）：
慢启动算法（Slow Start Algorithm）是TCP（Transmission Control Protocol）拥塞控制机制中的一个关键组件，用于在连接开始或恢复时，逐步增加发送数据的速率，以探测网络的承载能力和避免突然注入大量数据导致网络拥塞。

慢启动算法的基本思想如下：
1. **初始化拥塞窗口（cwnd）**：
   当一个新的TCP连接建立或在检测到数据包丢失后的恢复阶段，cwnd的初始值被设置为一个MSS（最大报文段大小）。这意味着最初只能发送一个MSS大小的数据。
2. **拥塞窗口增长**：
   每当收到一个对新发送的报文段的确认（ACK），cwnd将增加一个MSS的数值。在最初的几个RTT（往返时间）内，cwnd将以指数方式增长，即每收到一个ACK，cwnd就翻倍。
3. **慢开始门限（ssthresh）**：
   当cwnd的值达到或超过慢开始门限ssthresh时，慢启动算法结束，此时将转入拥塞避免算法。ssthresh的初始值通常是网络路径的最大可能带宽，但在连接恢复时，它会根据最近的拥塞事件进行调整。
4. **防止过快增长**：
   慢启动算法的目标是在网络达到其容量极限之前，逐步增加数据注入的速率。通过这种方式，网络可以逐渐适应新的流量，避免突然增加的数据量导致的拥塞。
5. **与拥塞避免算法的切换**：
   当cwnd等于ssthresh时，慢启动算法停止，系统进入拥塞避免算法阶段，此时cwnd的增长模式从指数级变为线性增长，以更细粒度地控制数据传输速率。
通过慢启动算法，TCP能够安全地探索网络的当前状况，避免在连接建立初期或恢复时因数据量过大而引发网络拥塞，从而确保数据传输的稳定性和网络的整体效率。

设置初始拥塞窗口大小为1，以后每收到一个应答拥塞窗口大小就加1（图中指定一个窗口大小是1000个字节），窗口大小呈指数级增长。客户端可发送数据的取拥塞窗口和应答包窗口两者中较小的那个

在TCP的慢启动算法中，拥塞窗口(cwnd)的大小最初被设置为一个报文段的大小（通常是一个MSS，最大报文段大小）。当一个确认到达时，cwnd会增加一个MSS的大小。这里的“增加1”实际上是指增加一个MSS的大小，而不是数值意义上的+1。

说慢启动是指数增长是因为在一个往返时间(RTT)内，cwnd的增长速度是呈指数级的。这里的关键在于，TCP允许在一个RTT内发送尽可能多的未确认的数据，只要不超过cwnd的大小。当第一个报文段被发送并收到确认后，cwnd会增加到2个MSS；当这两个报文段都得到确认后，cwnd又会翻倍到4个MSS；以此类推，在每一个RTT结束时，cwnd都会翻倍，这就是指数增长。

例如，如果MSS是1000字节，那么：

- 第一个RTT后，cwnd会从1个MSS（1000字节）增加到2个MSS（2000字节）。
- 第二个RTT后，cwnd会从2个MSS（2000字节）增加到4个MSS（4000字节）。
- 第三个RTT后，cwnd会从4个MSS（4000字节）增加到8个MSS（8000字节）。
- ...
- 以此类推，每过一个RTT，cwnd的大小都会翻倍。

这就是为什么说慢启动算法中的cwnd增长是指数级别的原因。然而，为了防止网络拥塞，当cwnd达到一个阈值（ssthresh）时，TCP会从慢启动阶段转到拥塞避免阶段，此时cwnd的增长速率会从指数级变为线性增长。
### 7.3.2 拥塞避免算法
-   拥塞避免算法与慢启动的区别在于，收到一个应答后，拥塞窗口大小cwnd只增加1/cwnd。窗口大小整体呈现线性增长。
1. **阈值检查**： 当拥塞窗口（cwnd）达到慢开始门限（ssthresh）时，慢开始算法停止，系统进入拥塞避免算法。ssthresh是一个动态调整的阈值，它的值通常在检测到网络拥塞时（如超时重传或接收到三个重复的ACKs）被减半。
    
2. **线性增长**： 在拥塞避免阶段，cwnd不再像慢开始阶段那样以指数方式增长，而是以线性方式增长。这意味着每经过一个往返时间（RTT），cwnd仅增加一个MSS（最大报文段大小）的值。这样可以更细粒度地控制数据传输速率，避免突然的流量激增。
    
3. **持续监控**： 在拥塞避免阶段，TCP会持续监控网络状态，如果再次检测到数据包丢失或网络拥塞的迹象，它会重新调整ssthresh和cwnd的值，有时会回到慢开始阶段，以更保守的方式重新探测网络的承载能力。
    
4. **与快速重传和快速恢复的交互**： 当接收到三个重复的ACKs时，这通常表示网络中有一个数据包丢失，但网络并未完全拥塞。这时，TCP会使用快速重传算法立即重传丢失的数据包，并进入快速恢复阶段，而不是将cwnd重置到1。在快速恢复结束后，如果cwnd小于ssthresh，它将继续增长直到达到ssthresh，然后进入拥塞避免阶段。
### 7.4 拥塞控制算法：
-   拥塞控制算法先采用慢启动算法，到达慢启动阀值后采用拥塞避免算法。

1.  通信开始时，发送方的拥塞窗口大小为 1。每收到一个 ACK 确认后，拥塞窗口大小加倍（not加1。
2.  由于指数级增长非常快，很快地，就会出现确认包超时，认为发生了拥塞。
3.  此时设置一个“慢启动阈值”，它的值是当前拥塞窗口大小的一半。
4.  拥堵发生后将拥塞窗口大小设置为 1，重新进入慢启动过程。
5.  由于现在“慢启动阈值”已经存在，当拥塞窗口大小达到阈值后，停止使用慢启动算法，开始采用拥塞避免算法。窗口大小开始线性增加。
6.  随着窗口大小不断增加，如果收到三次重复确认应答，则进入“快速重发”阶段。对于这用拥塞情况，TCP 将“慢启动阈值”设置为当前拥塞窗口大小的一半，再将拥塞窗口大小设置成阈值大小（也有说加 3）。然后采用拥塞避免算法增加窗口大小。
7.  随着窗口大小不断增加，如果发生超时。对于这种拥塞情况，TCP将满启动阀值设置为当前拥塞窗口的一半，然后将拥塞窗口设置为1。

![拥塞窗口](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7VebxkOb2wrp7LRc_u%2F-M7WPg6bpkfToPXatDC9%2Fimage.png?alt=media&token=bfaf86b5-b40e-4e42-98ca-ded2b4c674ae)


![加法增大、乘法减小](https://gblobscdn.gitbook.com/assets%2F-M75sygxWw2rOhVVFsMp%2F-M7VebxkOb2wrp7LRc_u%2F-M7WR-uFxQQxpHrcmEkH%2Fimage.png?alt=media&token=252296a1-9306-4235-a31d-ae72559a14b9)
拥塞控制中的“加法增大、乘法减小”（Additive Increase Multiplicative Decrease, AIMD）策略是一种广泛应用于TCP（传输控制协议）中的算法，用于在网络拥塞时调整数据传输速率，以避免网络过载并提高效率。这种策略的核心思想是在检测到网络拥塞时快速减少发送速率，而在网络状况良好时缓慢增加发送速率。
加法增大、乘法减小
1. **加法增大（Additive Increase）**：
    - 当网络没有拥塞迹象时，发送方会逐步增加其发送窗口大小，通常是每次增加一个MSS（最大段大小）单位。这意味着每收到一个ACK（确认），发送窗口就增加一个MSS的大小。这使得发送速率逐渐稳定增长，但不会迅速造成网络拥塞。
2. **乘法减小（Multiplicative Decrease）**：
    - 当检测到网络拥塞时，例如通过接收到三个重复的ACK或超时事件，发送方会大幅度减少其发送窗口大小，通常是将其减半。这种快速反应有助于防止网络进一步恶化。

AIMD策略的目标是在网络资源利用和避免拥塞之间找到平衡。通过加法增大，网络可以逐渐探索更高的带宽利用率，而通过乘法减小，它可以在检测到拥塞时迅速降低负载，从而保护网络免受过载的影响。


## 7.5 流量控制和拥塞控制的区别
### 7.5.1.流量控制和拥塞控制 相同点
-   （1）现象都是丢包；
-   （2）实现机制都是让发送方发的慢一点，发的少一点
### 7.5.2.流量控制和拥塞控制 不同点
-   1）丢包位置不同
    -   流量控制丢包位置是在接收端上
    -   拥塞控制丢包位置是在路由器上
-   （2）作用的对象不同
    -   流量控制的对象是接收方，怕发送方发的太快，使得接收方来不及处理
    -   拥塞控制的对象是网络，怕发送发发的太快，造成网络拥塞，使得网络来不及处理
### 7.5.3.流量控制和拥塞控制 联系
-   拥塞控制
    -   拥塞控制通常表示的是一个全局性的过程，它会涉及到网络中所有的主机、 所有的路由器和降低网络传输性能的所有因素
-   流量控制
    -   流量控制发生在发送端和接收端之间，只是点到点之间的控制
-   坚持定时器
    -   TCP不对ACK应答报文进行确认，如果接受端缓冲被占满，发送一个窗口为0的应答，过了一段时间数据处理完毕，重新发送一个应答，告诉发送端窗口大小。
    -   不幸的是，如果这个包丢了，就会进入死锁状态——发送端等待更新窗口的应答包，接收端等待接收数据。
    -   为了避免死锁了发生，TCP使用了一个坚持定时器来周期性地向接收方查询，以便发现窗口是否已经增大。这一过程也被称为窗口探查。

流量控制：流量控制主要是为了保护接收方免受发送方发送过多数据的影响，从而造成数据包的丢失、延迟等问题。流量控制通常由接收方来实现，通过通知发送方可以发送的数据的数量来限制发送方的传输速率。具体来说，当接收方处理速度跟不上发送方的数据发送速度时，会向发送方发送窗口大小的信息，告诉发送方当前可发送的数据量。发送方根据接收方提供的信息来调整自己的发送速率，确保发送的数据能够被接收方及时处理。

拥塞控制：拥塞控制主要是为了避免网络出现大量的数据包，从而导致网络拥堵、死锁等问题。拥塞控制通常由网络设备或者路由器来实现，通过检测网络拥塞的情况并采取相应的措施来调整发送速率，从而保证网络的正常运行。具体来说，当网络拥塞时，路由器会向发送方发送拥塞信号，告诉发送方当前网络拥塞的程度，从而限制发送方的传输速率，以降低网络拥堵的风险。

因此，流量控制和拥塞控制是处理数据传输时所采用的两种不同的策略，流量控制可以防止接收方被过多的数据包淹没，而拥塞控制则是为了保护整个网络不出现拥堵，从而提高网络的可靠性和稳定性。
[硬不硬你说了算！近 40 张图解被问千百遍的 TCP 三次握手和四次挥手面试题](https://mp.weixin.qq.com/s?__biz=MzAxODQxMDM0Mw==&mid=2247485167&idx=2&sn=19facbf79be561aee497e36d61d4c3a3&chksm=9bd7f8e7aca071f1d0330bf4aa8850e6ac050da7aad2af5a1b609e6a9c330b5b9c710ca6ddde&scene=21#wechat_redirect)


# 八、HTTP
### 8.1 HTTP 超文本传输协议
`HyperText Transfer Protocol`
超文本传输协议.

**HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范**

### 8.1.0 超文本

**超文本？**
超文本指的是`HTML，css，JavaScript和图片`等，HTTP的出现是为了接收和发布HTML页面，经过不断的发展也可以用于接收一些音频，视频，文件等内容。

### 8.1.1 HTTP

`HTTP`是基于客户端/服务端的架构模型，浏览器或其他任何客户端都可以用HTTP协议的，通过URL地址向HTTP的服务器即Web服务器发送所有请求，Web服务器端在接收到请求后会做出反应，响应给对方，就是向客户端回传响应的信息。

### 8.1.2 HTTP的特点：
> 支持客户端、服务器端模式，简单快速，客户端向服务器端请求服务时，只需传送请求方法和路径，灵活，HTTP允许传输任意类型的数据对象，无连接，限制每次连接只处理一个请求，无状态，
> HTTP协议是无状态协议，指明协议对于事务处理没有记忆能力。HTTP都是由客户端发起请求的，并且由服务器端回应响应消息的。

- 灵活，我们知道允许可以任何类型的数据对象，包括音频，视频，图片，文件等等。
- 无状态，HTTP就是说，每次HTTP请求都是独立的，任何两个请求之间没有必然的联系。
- 无连接的，每次服务器在处理完客户端的请求后，并收到客户的应答后，就断开了通信，当客户端再次发送请求时就是一个新的连接，采用这种方式可以节省传输时间。

**这是HTTP/1.0版的主要缺点，**每个TCP连接只能发送一个请求，发送数据完毕后，连接就关闭了，如果还要请求就必须要新建一个请求连接。
HTTP是一种不保存状态，无状态协议，协议对于发送过来的请求或是响应都不做持久化处理。
HTTP1.1虽然是无状态协议，但是为了实现期望的保持状态功能，于是引入了`Cookie技术`，有了Cookie，和HTTP协议通信，就可以管理状态了
### 8.1.3 HTTP消息的结构：
**请求消息的结构：**
一个请求消息是由**请求行，请求头字段，一个空行和消息主体**构成。
消息主体是响应消息的承载数据。

**客户端：** **发送请求**
客户端发送给某个HTTP服务器端的请求报文中的内容
```
GET/HTTP/1.1
Host: hackr.jp
```

**服务器：** **发送响应**
```
HTTP/1.1 200 OK
Date: Tue, 10 Jul ...
Content.Length: 362
Content.Type: text/html
<html>
...
```

GET，Request Method，请求方法，Request URL，为请求的url的地址，Status Code为状态码，Remote Address为地址。

HTTP是基于TCP/IP协议的应用层协议，不涉及数据包传输，规定了客户端和服务器端之间的通信方式，默认使用80端口，就如同他俩交流的语言。

### 8.2 HTTP状态码
**HTTP状态码是服务器端返回给客户端的。**
我们最常见的状态码为200，状态码200表示服务器响应成功，服务器找到了客户端请求的内容，并将内容发送给了客户端。
我们程序员有时候也常见的500，状态码500表示程序错误，就是说请求的网页程序本身就报错了。
现在的浏览器会对状态码500做出一定的处理，所以在一般情况下会返回一个定制的错误页面。
状态码404表示服务器上没有该资源，或者说是服务器上没有找到客户端请求的资源，是最常见的请求错误码。


### 8.3 方法
**Get 和 Post 是 HTTP 中最常用的两个方法**

1. GET为获取资源数据
    get方法用于请求指定的页面信息，并返回请求消息的主体
2. POST为提交资源数据
    post方法用于向指定的资源提交数据
3. PUT为更新资源数据
4. DELETE为删除资源数据
5. HEAD为读取资源的元数据
6. OPTIONS为读取资源多支持的所有请求方法
7. TRACE为回显服务器收到额请求
8. CONNECT为保留将来使用

## 8.4 HTTP1.0/1.1/2.0区别

### 8.4.1 HTTP 1.0

HTTP 1.0 是在 1996 年引入的，从那时开始，它的普及率就达到了惊人的效果。

- HTTP 1.0 仅仅提供了最基本的认证，这时候用户名和密码还`未经加密`，因此很容易收到窥探。
- HTTP 1.0 被设计用来使用`短链接`，即每次发送数据都会经过 TCP 的三次握手和四次挥手，效率比较低。
- HTTP 1.0 只使用 header 中的 If-Modified-Since 和 Expires 作为缓存失效的标准。
- HTTP 1.0 `不支持断点续传`，也就是说，每次都会传送全部的页面和数据。
- HTTP 1.0 认为每台计算机`只能绑定一个 IP`，所以请求消息中的 URL 并没有传递主机名（hostname）。

### 8.4.2 HTTP 1.1

HTTP 1.1 是 HTTP 1.0 开发三年后出现的，也就是 1999 年，它做出了以下方面的变化

- HTTP 1.1 使用了`摘要算法`来进行身份验证
- HTTP 1.1 默认使用`长连接`，长连接就是只需一次建立就可以传输多次数据，传输完成后，只需要一次切断连接即可。长连接的连接时长可以通过请求头中的 `keep-alive` 来设置
- HTTP 1.1 中新增加了 E-tag，If-Unmodified-Since, If-Match, If-None-Match 等`缓存控制标头`来控制缓存失效。
- HTTP 1.1 支持`断点续传`，通过使用请求头中的 `Range` 来实现。
- HTTP 1.1 使用了`虚拟网络`，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。

### 8.4.3 HTTP 2.0

HTTP 2.0 是 2015 年开发出来的标准，它主要做的改变如下

- `头部压缩`，由于 HTTP 1.1 经常会出现 **User-Agent、Cookie、Accept、Server、Range** 等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。HTTP 2.0 使用 `HPACK` 算法进行压缩。
- `二进制格式`，HTTP 2.0 使用了更加靠近 TCP/IP 的二进制格式，而抛弃了 ASCII 码，提升了解析效率
- `强化安全`，由于安全已经成为重中之重，所以 HTTP2.0 一般都跑在 HTTPS 上。
- `多路复用`，即每一个请求都是是用作连接共享。一个请求对应一个id，这样一个连接上可以有多个请求。
### 8.4.4 HTTP 3.0
HTTP/3（Hypertext Transfer Protocol version 3）是在HTTP/2的基础上发展起来的新一代网络传输协议，它主要解决了HTTP/2在某些方面存在的不足，尤其是在移动网络和高延迟网络环境下的性能问题。HTTP/3的主要特点是基于QUIC（Quick UDP Internet Connections）协议，而不是像HTTP/1.x和HTTP/2那样基于TCP。以下是HTTP/3的一些显著特点：

1. **基于UDP**：HTTP/3使用UDP作为传输层协议，而不是TCP。UDP提供了更低的延迟和更快的连接建立速度，因为它不需要等待三次握手完成。

2. **多路复用**：就像HTTP/2一样，HTTP/3也支持多路复用，即多个请求和响应可以在同一个连接上并发传输，但它是通过QUIC来实现这一点的。

3. **连接迁移**：QUIC支持无缝的连接迁移，这意味着如果客户端改变了IP地址或端口（例如，从Wi-Fi切换到蜂窝网络），连接不会断开，从而减少了重新建立连接的时间。

4. **降低延迟**：由于QUIC的快速重传机制和拥塞控制算法，HTTP/3能够更快地检测到数据包丢失并重新发送，从而降低了延迟。

5. **加密连接**：HTTP/3默认使用TLS加密整个连接，包括握手阶段。这提高了安全性，并减少了握手延迟，因为TLS握手可以在0-RTT（零往返时间）下完成。

6. **错误恢复**：QUIC允许部分数据包丢失后仅重传丢失的数据包，而不是像TCP那样重新传输整个流。这提高了效率并减少了重传延迟。

7. **更好的拥塞控制**：QUIC使用更先进的拥塞控制算法，如BBR（Bottleneck Bandwidth and RTT），这有助于在网络拥塞时更好地管理流量。

8. **减少头部阻塞**：由于QUIC的流控机制，HTTP/3可以避免HTTP/2中的头部阻塞问题，即使在处理大型头部时也能保持高性能。

9. **改进的握手延迟**：QUIC的握手延迟比TCP+TLS更短，因为它减少了握手过程中所需的往返次数。

10. **标准化**：HTTP/3是IETF的一个标准项目，旨在提高Web性能和安全性。

总的来说，HTTP/3旨在提高Web应用程序的性能，特别是在移动设备和不稳定网络环境下。通过利用QUIC协议的优势，HTTP/3能够在保持安全性的同时，提供更快的加载时间和更好的用户体验。

### 8.5 HTTP 常见的请求头
`通用标头`、`实体标头`、`请求标头`、`响应标头`
通用标头（General Headers）：这些头部在请求和响应消息中都可以出现，但与消息主体本身的数据无关。例如：Date, Cache-Control 和 Connection。
实体标头（Entity Headers）：这些头部包含有关消息主体的信息，例如其内容长度和MIME类型。例如：Content-Type, Content-Length 和 Content-Encoding。
请求标头（Request Headers）：这些头部特定于HTTP请求，并提供了有关请求或有关客户端本身的信息。例如：Host, User-Agent 和 Accept。
响应标头（Response Headers）：这些头部特定于HTTP响应，提供了有关响应和服务器本身的信息。例如：Server, WWW-Authenticate 和 Set-Cookie.
这些都是为了使HTTP协议具有良好的扩展性和灵活性，以处理各种类型的网络请求和响应。

### 8.5.1 通用标头
HTTP 通用标头之所以这样命名，是因为与其他三个类别不同，它们不是限定于特定种类的消息或者消息组件（请求，响应或消息实体）的。HTTP 通用标头主要用于传达有关消息本身的信息，而不是它所携带的内容。它们提供一般信息并控制如何处理和处理消息。

尽管通用标头不会限定于是请求还是响应报文，但是某些通用标头大部分或全部用于一种特定类型的请求中。也就是说，如果某个通用标头出现在请求报文中，那么大部分通用标头都会显示在该请求报文中。响应报文也是一样的。
通用标头主要有三个，分别是 `Date`、`Cache-Control` 和 `Connection`

#### 8.5.1.1 Date
Date 是一个通用标头，它可以出现在请求标头和响应标头中，它的基本表示如下
`Date: Wed, 21 Oct 2015 07:28:00 GMT `
表示的是格林威治标准时间，这个时间要比北京时间慢八个小时
#### 8.5.1.2 Cache-Control
Cache-Control 是一个通用标头，他可以出现在请求标头和响应标头中，Cache-Control 的种类比较多，虽然说这是一个通用标头，但是有一些特性是请求标头具有的，有一些是响应标头才有的。
主要大类有 可缓存性、阈值性、 重新验证并重新加载 和其他特性
#### 8.5.1.3 Connection
Connection 决定当前事务（一次三次握手和四次挥手）完成后，是否会关闭网络连接。Connection 有两种，
一种是持久性连接，即一次事务完成后不关闭网络连接
`Connection: keep-alive`
另一种是非持久性连接，即一次事务完成后关闭网络连接
`Connection: close`

### 8.5.2 实体标头
实体标头不局限于请求标头或者响应标头
实体标头是描述消息正文内容的 HTTP 标头。实体标头用于 HTTP 请求和响应中。头部`Content-Length`、 `Content-Language`、 `Content-Encoding` 是实体头。

- `Content-Length` 实体报头指示实体主体的大小，以字节为单位，发送到接收方。
- `Content-Language` 实体报头描述了客户端或者服务端能够接受的语言。
- `Content-Encoding` 这又是一个比较麻烦的属性，这个实体报头用来压缩媒体类型。Content-Encoding 指示对实体应用了何种编码。
    常见的内容编码有这几种： `gzip`、`compress`、`deflate`、`identity`，这个属性可以应用在请求报文和响应报文中
### 8.5.3 请求标头
请求标头用于客户端发送 HTTP 请求到服务器中所使用的字段
#### 8.5.3.1 Host
Host 请求头指明了服务器的域名（对于虚拟主机来说），以及（可选的）服务器监听的 TCP 端口号。如果没有给定端口号，会自动使用被请求服务的默认端口（比如请求一个 HTTP 的 URL 会自动使用 80 作为端口）。

```
Host: developer.mozilla.org
```
上面的 `Accpet`、 `Accept-Language`、`Accept-Encoding` 都是属于内容协商的请求标头。

#### 8.5.3.2 Referer
HTTP Referer 属性是请求标头的一部分，当浏览器向 web 服务器发送请求的时候，一般会带上 Referer，告诉服务器该网页是从哪个页面链接过来的，服务器因此可以获得一些信息用于处理。

```
Referer: https://developer.mozilla.org/testpage.html
```
#### 8.5.3.3 If-Modified-Since
If-Modified-Since 通常会与 If-None-Match 搭配使用，If-Modified-Since 用于确认代理或客户端拥有的本地资源的有效性。获取资源的更新日期时间，可通过确认首部字段 `Last-Modified` 来确定。
大白话说就是如果在 `Last-Modified` 之后更新了服务器资源，那么服务器会响应 200，如果在 `Last-Modified` 之后没有更新过资源，则返回 304。
```
If-Modified-Since: Mon, 18 Jul 2016 02:36:04 GMT
```

#### 8.5.3.4 If-None-Match
If-None-Match HTTP 请求标头使请求成为条件请求。对于 GET 和 HEAD 方法，仅当服务器没有与给定资源匹配的 `ETag` 时，服务器才会以 200 状态发送回请求的资源。对于其他方法，仅当最终现有资源的`ETag`与列出的任何值都不匹配时，才会处理请求。
```
If-None-Match: "c561c68d0ba92bbeb8b0fff2a9199f722e3a621a"
```

#### 8.5.3.5 Accept
接受请求 HTTP 标头会通告客户端其能够理解的 MIME 类型
> “MIME: MIME (Multipurpose Internet Mail Extensions) 是描述消息内容类型的因特网标准。MIME 消息能包含文本、图像、音频、视频以及其他应用程序专用的数据。

#### 8.5.3.6 Accept-Charset
accept-charset 属性规定服务器处理表单数据所接受的字符集。
常用的字符集有：UTF-8 - Unicode 字符编码 ；ISO-8859-1 - 拉丁字母表的字符编码

#### 8.5.3.7 Accept-Language
首部字段 Accept-Language 用来告知服务器用户代理能够处理的自然语言集（指中文或英文等），以及自然语言集的相对优先级。可一次指定多种自然语言集。

### 8.5.4 响应标头

#### 8.5.4.1 Access-Control-Allow-Origin
一个返回的 HTTP 标头可能会具有 Access-Control-Allow-Origin ，`Access-Control-Allow-Origin` 指定一个来源，它告诉浏览器允许该来源进行资源访问。
#### 8.5.4.2 Keep-Alive
Keep-Alive 表示的是 Connection 非持续连接的存活时间，可以进行指定。
#### 8.5.4.3 Server
服务器标头包含有关原始服务器用来处理请求的软件的信息。
应该避免使用过于冗长和详细的 Server 值，因为它们可能会泄露内部实施细节，这可能会使攻击者容易地发现并利用已知的安全漏洞。例如下面这种写法
```
Server: Apache/2.4.1 (Unix)
```
#### 8.5.4.4 Set-Cookie
Set-Cookie 用于服务器向客户端发送 sessionID。
#### 8.5.4.5 Transfer-Encoding
首部字段 Transfer-Encoding 规定了传输报文主体时采用的编码方式。
HTTP /1.1 的传输编码方式仅对分块传输编码有效。
#### 8.5.4.6 X-Frame-Options
HTTP 首部字段是可以自行扩展的。所以在 Web 服务器和浏览器的应用上，会出现各种非标准的首部字段。
首部字段 `X-Frame-Options` 属于 HTTP 响应首部，用于控制网站内容在其他 Web 网站的 Frame 标签内的显示问题。其主要目的是为了防止点击劫持（clickjacking）攻击。

### 8.6 地址栏输入 URL 发生了什么？
1. DNS
DNS 的全称是 Domain Name System 域名系统。DNS 是一种由分层的 DNS 服务器实现的分布式数据库。DNS 运行在 UDP 上，使用 53 端口。
浏览器会根据你输入的 URL 地址，去查找域名是否被本地 DNS 缓存，不同浏览器对 DNS 的设置不同。
2. 在由根域名服务器 -> 顶级域名服务器 -> 权威 DNS 服务器后，由权威服务器告诉本地服务器目标 IP 地址，再有本地 DNS 服务器告诉用户需要访问的 IP 地址。
3. 第三步，浏览器需要和目标服务器建立 TCP 连接，需要经过三次握手的过程，具体的握手过程请参考上面的回答。
- 在建立连接后，浏览器会向目标服务器发起 `HTTP-GET` 请求，包括其中的 URL，HTTP 1.1 后默认使用长连接，只需要一次握手即可多次传输数据。
- 如果目标服务器只是一个简单的页面，就会直接返回。但是对于某些大型网站的站点，往往不会直接返回主机名所在的页面，而会直接重定向。返回的状态码就不是 200 ，而是 301,302 以 3 开头的重定向码，浏览器在获取了重定向响应后，在响应报文中 Location 项找到重定向地址，浏览器重新第一步访问即可。
- 然后浏览器重新发送请求，携带新的 URL，返回状态码 200 OK，表示服务器可以响应请求，返回报文。

# 九、HTTPS
MITM（Man In The Middle）中间人攻击
### 9.0 Hypertext Transfer Protocol Secure
**HTTPS** 的全称是 `Hypertext Transfer Protocol Secure`
**HTTP + TLS/SSL** 协议组合而成，而安全性的保证正是 TLS/SSL 所做的工作。

HTTPS 是安全的协议，它通过 **密钥交换算法 - 签名算法 - 对称加密算法 - 摘要算法** 能够解决上面这些问题。

HTTP 的默认端口是 80，而 HTTPS 的默认端口是 443。

### 9.1 HTTPS做了什么
HTTPS 协议提供了三个关键的指标

-   `加密(Encryption)`， HTTPS 通过对[数据加密](https://cloud.tencent.com/solution/domesticencryption?from=10680)来使其免受窃听者对数据的监听，这就意味着当用户在浏览网站时，没有人能够监听他和网站之间的信息交换，或者跟踪用户的活动，访问记录等，从而窃取用户信息。
-   `数据一致性(Data integrity)`，数据在传输的过程中不会被窃听者所修改，用户发送的数据会`完整`的传输到服务端，保证用户发的是什么，[服务器](https://cloud.tencent.com/product/cvm?from=10680)接收的就是什么。
-   `身份认证(Authentication)`，是指确认对方的真实身份，也就是`证明你是你`（可以比作人脸识别），它可以防止中间人攻击并建立用户信任。

### 9.2 HTTPS 的握手过程，其实就是 SSL/TLS 的握手过程

TLS 旨在为 Internet 提供通信安全的加密协议。
`TLS(Transport Layer Security)` 是 `SSL(Secure Socket Layer)` 的后续版本，它们是用于在互联网两台计算机之间用于`身份验证`和`加密`的一种协议。
TLS 握手是启动和使用 TLS 加密的通信会话的过程。在 TLS 握手期间，Internet 中的通信双方会彼此交换信息，验证密码套件，交换会话密钥。

TLS 具体的握手过程会根据所使用的`密钥交换算法的类型`和双方支持的`密码套件`而不同。我们以`RSA 非对称加密`来讨论这个过程。

1. 在进行通信前，首先会进行 **HTTP 的三次握手**，握手完成后，再进行 TLS 的握手过程
2. `ClientHello`：客户端通过向服务器发送 `hello` 消息来发起握手过程。
    这个消息中会夹带着客户端支持的 `TLS 版本号(TLS1.0 、TLS1.2、TLS1.3)` 、客户端支持的密码套件、以及一串 `客户端随机数`。
3. `ServerHello`：在客户端发送 hello 消息后，服务器会发送一条消息，这条消息包含了服务器的 SSL 证书、服务器选择的密码套件和服务器生成的随机数。
4. `认证(Authentication)`：客户端的证书颁发机构会认证 SSL 证书，然后发送 `Certificate` 报文，报文中包含公开密钥证书。
    最后服务器发送 `ServerHelloDone` 作为 `hello` 请求的响应。第一部分握手阶段结束。
5. `加密阶段`：在第一个阶段握手完成后，客户端会发送 `ClientKeyExchange` 作为响应，这个响应中包含了一种称为 `The premaster secret` 的密钥字符串，这个字符串就是使用上面公开密钥证书进行加密的字符串。
    随后客户端会发送 `ChangeCipherSpec`，告诉服务端使用私钥解密这个 `premaster secret` 的字符串，然后客户端发送 `Finished` 告诉服务端自己发送完成了。

> Session key 其实就是用公钥证书加密的公钥。
- `实现了安全的非对称加密`：然后，服务器再发送 `ChangeCipherSpec` 和 `Finished` 告诉客户端解密完成，至此实现了 RSA 的非对称加密。

### 9.3 HTTPS的加解密流程
1. 用户在浏览器发起HTTPS请求，默认使用服务端的443端口进行连接；
2. HTTPS需要使用一套**CA数字证书**，证书内会附带一个**公钥Pub**，而与之对应的**私钥Private**保留在服务端不公开；
3. 服务端收到请求，返回配置好的包含**公钥Pub**的证书给客户端；
4. 客户端收到**证书**，校验合法性，主要包括是否在有效期内、证书的域名与请求的域名是否匹配，上一级证书是否有效（递归判断，直到判断到系统内置或浏览器配置好的根证书），如果不通过，则显示HTTPS警告信息，如果通过则继续；
5. 客户端生成一个用于对称加密的**随机Key**，并用证书内的**公钥Pub**进行加密，发送给服务端；
6. 服务端收到**随机Key**的密文，使用与**公钥Pub**配对的**私钥Private**进行解密，得到客户端真正想发送的**随机Key**；
7. 服务端使用客户端发送过来的**随机Key**对要传输的HTTP数据进行对称加密，将密文返回客户端；
8. 客户端使用**随机Key**对称解密密文，得到HTTP数据明文；
9. 后续HTTPS请求使用之前交换好的**随机Key**进行对称加解密。

### 9.4 CA颁发机构

依然考虑**中间人攻击**的情况，非对称加密的算法都是**公开**的，所有人都可以自己生成一对公钥私钥。

当服务端向客户端返回公钥A1的时候，中间人将其**替换**成自己的公钥B1传送给浏览器。

而浏览器此时一无所知，傻乎乎地使用公钥B1加密了密钥K发送出去，又被**中间人截获**，中间人利用自己的私钥B2解密，得到密钥K，再使用服务端的公钥A1加密传送给服务端，完成了通信链路，而服务端和客户端毫无感知。

出现这一问题的核心原因是**客户端无法确认收到的公钥是不是真的是服务端发来的**。为了解决这个问题，互联网引入了一个公信机构，这就是CA。

服务端在使用HTTPS前，去经过认证的CA机构申请颁发一份**数字证书**，数字证书里包含有证书持有者、证书有效期、公钥等信息，服务端将证书发送给客户端，客户端校验证书身份和要访问的网站身份确实一致后再进行后续的加密操作。

但是，如果中间人也聪明一点，**只改动了证书中的公钥部分**，客户端依然不能确认证书**是否被篡改**，这时我们就需要一些防伪技术了。

前面说过，非对称加密中一般公钥用来加密，私钥用来解密，虽然私钥加密理论上可行，但由于数学上的设计这么做并不适合，那么私钥就只有解密这个功能了么？

私钥除了解密外的真正用途其实还有一个，就是**数字签名**，其实就是一种防伪技术，只要有人篡改了证书，那么数字签名必然校验失败。具体过程如下

1. CA机构拥有自己的一对公钥和私钥
2. CA机构在颁发证书时对证书明文信息进行哈希
3. 将哈希值用私钥进行**加签**，得到数字签名

**明文数据和数字签名组成证书，传递给客户端。**

1. 客户端得到证书，分解成明文部分Text和数字签名Sig1
2. 用CA机构的公钥进行**解签**，得到Sig2（由于CA机构是一种公信身份，因此在系统或浏览器中会内置CA机构的证书和公钥信息）
3. 用证书里声明的哈希算法对明文Text部分进行哈希得到H
4. 当自己计算得到的哈希值T与**解签**后的Sig2**相等**，表示证书可信，**没有被篡改**

这时，签名是由CA机构的私钥生成的，中间人篡改信息后无法拿到CA机构的私钥，保证了证书可信。

>小林coding

CA（Certification Authority，认证机构）是一个受信任的第三方实体，它的主要职责是验证数字证书申请者的身份，并为验证过的申请者签发数字证书。这些数字证书包含了申请者的公钥和其他相关信息，并由CA使用自己的私钥进行了数字签名。这样做的目的是确保证书的完整性和真实性，防止证书被伪造或篡改。

当一个实体（比如一个Web服务器或个人）想要与另一个实体建立安全的通信时，它们会使用数字证书来确认彼此的身份。证书上的数字签名确保了证书的内容自签发以来没有被篡改过。

#### 9.4.1 如何确保证书没有被篡改？

1. **数字签名**：
   - 每个CA都有一个公钥/私钥对。当CA签发证书时，它会在证书上加上自己的数字签名。这个签名是使用CA的私钥创建的，任何人都可以用CA的公钥来验证签名。
   
2. **验证过程**：
   - 接收方（如Web浏览器）在接收到一个证书后，会尝试验证证书上的数字签名。这通常是通过一个称为证书链的过程完成的。
   
3. **证书链**：
   - 数字证书通常有一个层次结构，即从最终实体证书到根证书的一系列证书。每个证书都由下一个证书在链中进行签名，直到到达根证书。根证书通常预装在操作系统或浏览器中，并被视为完全可信的。
   
4. **根证书的信任**：
   - 根证书是整个证书链的顶端，它们存储在用户的设备上，并被默认信任。因此，如果证书链可以追溯到一个信任的根证书，那么证书就被认为是有效的。
   
5. **证书撤销列表 (CRL) 和在线证书状态协议 (OCSP)**：
   - 如果证书被撤销（例如，因为私钥泄露），CA会将其添加到证书撤销列表（CRL）中。客户端可以通过下载CRL或使用OCSP来检查证书是否已被撤销。

#### 9.4.2 示例流程

1. 用户访问一个网站。
2. 网站向用户发送其数字证书。
3. 用户的浏览器检查证书上的数字签名是否匹配CA的公钥。
4. 如果签名匹配，浏览器还会检查证书的有效期、域名是否正确，以及证书是否在CRL中被标记为撤销。
5. 如果一切正常，浏览器就会接受证书，并继续建立安全连接。

总之，CA通过使用数字签名来保证证书的真实性和完整性。用户通过验证这些签名和检查证书链来确定证书是否被篡改。如果证书被篡改或伪造，验证过程将会失败，因为篡改后的证书无法通过CA的公钥验证。

## 9.5 加密
### 9.5.1 对称加密
`对称加密(Symmetrical Encryption)`顾名思义就是指**加密和解密时使用的密钥都是同样的密钥**。只要保证了密钥的安全性，那么整个通信过程也就是具有了机密性。
TLS 里面有比较多的加密算法可供使用，比如 DES、3DES、AES、ChaCha20、TDEA、Blowfish、RC2、RC4、RC5、IDEA、SKIPJACK 等。目前最常用的是 AES-128, AES-192、AES-256 和 ChaCha20。

`DES` 的全称是 `Data Encryption Standard(数据加密标准)` ，它是用于数字数据加密的对称密钥算法。尽管其 56 位的短密钥长度使它对于现代应用程序来说太不安全了，但它在加密技术的发展中具有很大的影响力。

`3DES` 是从原始数据加密标准（DES）衍生过来的加密算法，它在 90 年代后变得很重要，但是后面由于更加高级的算法出现，3DES 变得不再重要。

AES-128, AES-192 和 AES-256 都是属于 AES ，AES 的全称是`Advanced Encryption Standard(高级加密标准)`，它是 DES 算法的替代者，安全强度很高，性能也很好，是应用最广泛的对称加密算法。

 ### 9.5.2 **非对称加密**

`非对称加密(Asymmetrical Encryption)` 也被称为`公钥加密`，相对于对称加密来说，非对称加密是一种新的改良加密方式。密钥通过网络传输交换，它能够确保及时密钥被拦截，也不会暴露数据信息。非对称加密中有两个密钥，一个是公钥，一个是私钥，公钥进行加密，私钥进行解密。公开密钥可供任何人使用，私钥只有你自己能够知道。
非对称加密算法的设计要比对称算法难得多（我们不会探讨具体的加密方式），常见的比如 DH、DSA、RSA、ECC 等。

其中 `RSA` 加密算法是最重要的、最出名的一个了。例如 `DHE_RSA_CAMELLIA128_GCM_SHA256`。它的安全性基于 `整数分解`，使用两个超大素数的乘积作为生成密钥的材料，想要从公钥推算出私钥是非常困难的。

## 9.6 TLS/SSL
TLS（Transport Layer Security，传输层安全协议）和SSL（Secure Sockets Layer，安全套接层协议）都是用于加密互联网通信的安全协议。它们的主要目的是保护客户端和服务器之间的数据传输免受窃听、篡改和消息伪造等攻击。

### 9.6.1 SSL vs TLS 的主要区别

#### 1. **历史背景**
- **SSL** 是由 Netscape 开发的第一种安全协议，最初版本为 SSL 1.0（从未公开发布），后续发布了 SSL 2.0 和 SSL 3.0。
- **TLS** 是 IETF（Internet Engineering Task Force，互联网工程任务组）在 SSL 的基础上发展而来，旨在标准化 SSL 协议，并改进其中的一些弱点。TLS 的第一个版本是 TLS 1.0，发布于 1999 年。

#### 2. **协议版本**
- **SSL** 的版本主要包括 SSL 1.0（未发布）、SSL 2.0 和 SSL 3.0。
- **TLS** 的版本主要包括 TLS 1.0、TLS 1.1、TLS 1.2 和 TLS 1.3。

#### 3. **安全性**
- **SSL** 的早期版本存在一些已知的安全漏洞，例如 POODLE 攻击针对 SSL 3.0。
- **TLS** 在安全性方面进行了改进，修复了一些 SSL 中存在的漏洞，并引入了更强大的加密算法和技术。

#### 4. **握手协议**
- **SSL** 和 **TLS** 的握手协议略有不同，TLS 在握手过程中增加了更多的安全机制。
- 例如，TLS 引入了 Client Key Exchange、Server Key Exchange 等阶段，并且增强了身份验证过程。

#### 5. **加密算法**
- **TLS** 支持更多种类的加密算法，包括更现代的加密套件，例如 AES（Advanced Encryption Standard）等。
- **TLS 1.3** 特别强调了对加密算法的支持，移除了许多不再安全的算法，并引入了新的密钥交换机制，如 ECDHE（Elliptic Curve Diffie-Hellman Ephemeral）。

#### 6. **性能**
- **TLS 1.3** 在性能方面做了优化，减少了握手次数，并支持了0-RTT（零往返时间）握手，从而提高了连接建立的速度。

### 9.6.2 TLS/SSL总结

- **SSL** 通常指的是 SSL 3.0 及其之前的版本，由于存在安全漏洞，现在已经被弃用。
- **TLS** 是当前广泛使用的安全协议标准，它继承了 SSL 的基本思想，但进行了大量改进，以提高安全性、可靠性和性能。
- 在实际应用中，我们通常说的“SSL证书”实际上是指支持TLS协议的数字证书，尽管名称上仍然保留了“SSL”这一术语。

### 9.6.3 TLS/SSL实际应用中的建议

在实际部署中，应尽可能使用最新的 TLS 版本（目前是 TLS 1.3），以获得最佳的安全性和性能。同时，应该禁用 SSL 3.0 及更早的版本，以防止潜在的安全风险。

### 9.6.4 程序中选择TLS/SSL在不同库中的实现
在程序中控制使用 TLS（传输层安全协议）或 SSL（安全套接字层）通常取决于你使用的库和上下文。TLS 是 SSL 的继任者，提供了更安全的加密和认证机制。现代应用程序通常推荐使用 TLS 而不是 SSL。

#### 9.6.4.1 OpenSSL使用SSL/TLS
OpenSSL 是一个广泛使用的开源库，支持 SSL 和 TLS 协议。你可以通过设置适当的选项来指定使用 TLS 或 SSL。

```cpp
#include <openssl/ssl.h>
#include <openssl/err.h>

// 初始化 OpenSSL 库
SSL_library_init();
SSL_load_error_strings();
OpenSSL_add_all_algorithms();

// 创建 SSL 上下文
const SSL_METHOD *method;
SSL_CTX *ctx;

// 使用 TLSv1.2 方法
method = TLS_method(); // 使用 TLS
// method = SSLv23_method(); // 兼容模式，可以协商使用 SSLv2, SSLv3, TLSv1, TLSv1.1, TLSv1.2

ctx = SSL_CTX_new(method);
if (ctx == NULL) {
    ERR_print_errors_fp(stderr);
    exit(EXIT_FAILURE);
}

// 设置 SSL/TLS 版本
SSL_CTX_set_min_proto_version(ctx, TLS1_2_VERSION); // 最低版本为 TLS 1.2
SSL_CTX_set_max_proto_version(ctx, TLS1_2_VERSION); // 最高版本为 TLS 1.2

// 创建 SSL 连接
SSL *ssl = SSL_new(ctx);
BIO *bio = BIO_new_ssl_connect(ctx);

// 设置连接参数
BIO_set_conn_hostname(bio, "example.com:443");

// 连接到服务器
if (BIO_do_connect(bio) <= 0) {
    ERR_print_errors_fp(stderr);
    exit(EXIT_FAILURE);
}

// 执行 SSL 握手
if (SSL_do_handshake(ssl) <= 0) {
    ERR_print_errors_fp(stderr);
    exit(EXIT_FAILURE);
}

// 现在可以进行加密通信了
```

#### 9.6.4.2 GnuTLS的TLS 和 SSL 协议
GnuTLS 是另一个常用的库，支持 TLS 和 SSL 协议。

```c
#include <gnutls/gnutls.h>

int main() {
    gnutls_certificate_credentials_t xcred;
    gnutls_session_t session;

    // 初始化 GnuTLS 库
    gnutls_global_init();

    // 创建证书凭据
    gnutls_certificate_allocate_credentials(&xcred);

    // 创建会话
    gnutls_init(&session, GNUTLS_CLIENT);

    // 设置优先级字符串以选择 TLS 版本
    gnutls_priority_set_direct(session, "NORMAL:%COMPAT", NULL);

    // 设置证书凭据
    gnutls_credentials_set(session, GNUTLS_CRD_CERTIFICATE, xcred);

    // 设置目标主机名
    gnutls_server_name_set(session, GNUTLS_NAME_DNS, "example.com", 0);

    // 建立连接（这里需要自己实现网络连接部分）
    // ...

    // 执行握手
    gnutls_handshake(session);

    // 现在可以进行加密通信了
    // ...

    // 清理资源
    gnutls_deinit(session);
    gnutls_certificate_free_credentials(xcred);
    gnutls_global_deinit();

    return 0;
}
```

#### 9.6.4.3 Boost.Asio with OpenSSL
如果你使用 Boost.Asio 结合 OpenSSL，可以通过设置 SSL/TLS 上下文来控制使用的协议版本。

```cpp
#include <boost/asio.hpp>
#include <boost/asio/ssl.hpp>
#include <iostream>

int main() {
    try {
        boost::asio::io_context io_context;

        // 创建 SSL 上下文
        boost::asio::ssl::context ctx(boost::asio::ssl::context::tlsv12);

        // 设置 SSL/TLS 版本
        ctx.set_options(
            boost::asio::ssl::context::default_workarounds |
            boost::asio::ssl::context::no_sslv2 |
            boost::asio::ssl::context::no_sslv3 |
            boost::asio::ssl::context::single_dh_use
        );

        // 创建 SSL 流
        boost::asio::ip::tcp::resolver resolver(io_context);
        boost::asio::ssl::stream<boost::asio::ip::tcp::socket> ssl_stream(io_context, ctx);

        // 解析目标地址
        auto endpoints = resolver.resolve("example.com", "https");

        // 连接到服务器
        boost::asio::connect(ssl_stream.lowest_layer(), endpoints);

        // 执行 SSL 握手
        ssl_stream.handshake(boost::asio::ssl::stream_base::client);

        // 现在可以进行加密通信了
        std::cout << "Connected and handshake completed." << std::endl;

    } catch (std::exception& e) {
        std::cerr << "Exception: " << e.what() << "\n";
    }

    return 0;
}
```

#### 9.6.4.4 TLS/SSL 库使用总结
- **OpenSSL**：通过 `SSL_CTX_set_min_proto_version` 和 `SSL_CTX_set_max_proto_version` 来设置最小和最大协议版本。
- **GnuTLS**：通过 `gnutls_priority_set_direct` 设置优先级字符串来选择协议版本。
- **Boost.Asio with OpenSSL**：通过 `boost::asio::ssl::context` 构造函数和 `set_options` 方法来设置协议版本。

这些方法允许你在程序中明确指定使用 TLS 或 SSL，并且可以根据需要选择具体的协议版本。
# 十、TCP 三次握手的性能提升
### 10.1 TCP 三次握手的性能提升 - 客户端优化
三次握手建立连接的首要目的是「同步序列号」。
只有同步了序列号才有可靠传输，TCP 许多特性都依赖于序列号实现，比如流量控制、丢包重传等，这也是三次握手中的报文称为 SYN 的原因，
SYN 的全称就叫 `Synchronize Sequence Numbers`（同步序列号）。

### 10.1.1 TCP 三次握手的性能提升 - SYN_SENT 状态的优化
客户端作为主动发起连接方，首先它将发送 SYN 包，于是客户端的连接就会处于 `SYN_SENT` 状态。
客户端在等待服务端回复的 ACK 报文，正常情况下，服务器会在几毫秒内返回 SYN+ACK ，但如果客户端长时间没有收到 SYN+ACK 报文，则会重发 SYN 包，
重发的次数由 tcp_syn_retries 参数控制，默认是 5 次：

```shell
# tcp_syn_retries,控制SYN重发次数
cat  /proc/sys/net/ipv4/tcp_syn_retries
5
```
通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，每次超时的时间是上一次的 2 倍。
当第五次超时重传后，会继续等待 32 秒，如果仍然服务端没有回应 ACK，客户端就会终止三次握手。
所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。

可以调整客户端的`三次握手时间次数上限`。比如内网中通讯时，就可以适当调低重试次数，尽快把错误暴露给应用程序。

### 10.2 TCP 三次握手的性能提升 - 服务端优化
当服务端收到 SYN 包后，服务端会立马回复 `SYN+ACK` 包，表明确认收到了客户端的序列号，同时也把自己的序列号发给对方。
此时，服务端出现了新连接，状态是 `SYN_RCV`。
在这个状态下，Linux 内核就会建立一个「半连接队列」来维护「未完成」的握手信息，当半连接队列溢出后，服务端就无法再建立新的连接。
SYN 攻击，攻击的是就是这个半连接队列。

> 如何查看由于 SYN 半连接队列已满，而被丢弃连接的情况？
> 我们可以通过该 netstat -s 命令给出的统计结果中，  可以得到由于半连接队列已满，引发的失败次数：
```shell
 netstat -s | grep "Syns to LISTEN"
```
上面输出的数值是累计值，表示共有多少个 TCP 连接因为半连接队列溢出而被丢弃。隔几秒执行几次，如果有上升的趋势，说明当前存在半连接队列溢出的现象。

### 10.2.1 TCP 三次握手的性能提升 - 调整 SYN 半连接队列大小
1. 内核参数`net.ipv4.tcp_max_syn_backlog`定义了处于`SYN_RECV`的TCP最大连接数，
    当处于`SYN_RECV`状态的TCP连接数超过`tcp_max_syn_backlog`后，会丢弃后续的SYN报文。
2. 使用该端口的程序中`listen(`)函数.关于`somaxconn`参数:定义了系统中每一个端口最大的监听队列的长度,这是个全局的参数,默认值为128,
3. `backlog` 参数描述的是服务器端 TCP `ESTABELLISHED `状态对应的全连接队列长度。

要想增大半连接队列，不能只单纯增大 `tcp_max_syn_backlog` 的值，还需一同增大 `somaxconn` 和 `backlog`，也就是增大 accept 队列。
否则，只单纯增大 `tcp_max_syn_backlog` 是无效的。

1. 增大 `tcp_max_syn_backlog` 和 `somaxconn` 的方法是修改 Linux 内核参数：
```shell
# tcp_max_syn_backlog
cat /proc/sys/net/ipv4/tcp_max_syn_backlog
512
# somaxconn
cat /proc/sys/net/core/somaxconn
128
```
2. 增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：
```shell
/usr/local/nginx/conf/nginx.conf
server {
           listen 8080 default backlog=1024;
           server_name localhost;
           ...
}
```

如果 SYN 半连接队列已满，只能丢弃连接吗？
### 10.2.2 开启` syncookies` 功能就可以在 **不使用 SYN 半连接队列** 的情况下成功建立连接。

syncookies 的工作原理：
    服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。

syncookies 参数主要有以下三个值：

- 0 值，表示关闭该功能；
- 1 值，表示仅当 SYN 半连接队列放不下时，再启用它；
- 2 值，表示无条件开启功能；

```shell
# 可以设置syncoolies
cat  /proc/sys/net/ipv4/tcp_syncookies
1
```

### 10.2.3 SYN_RCV 状态的优化，修改重发SYN-ACK
当客户端接收到服务器发来的 `SYN+ACK` 报文后，就会回复 `ACK`给服务器，同时客户端连接状态从`SYN_SENT` 转换为 `ESTABLISHED`，表示连接建立成功。
服务器端连接成功建立的时间还要再往后，等到服务端收到客户端的 `ACK` 后，服务端的连接状态才变为 `ESTABLISHED`。
如果服务器没有收到 `ACK`，就会重发 `SYN+ACK` 报文，同时一直处于 `SYN_RCV` 状态。

当网络繁忙、不稳定时，报文丢失就会变严重，此时应该`调大重发次数`。反之则可以`调小重发次数`。
修改重发次数的方法是，调整 `tcp_synack_retries` 参数：
```shell
# 参数tcp_synack_retries控制SYN-ACK包重发次数，默认5次
cat /proc/sys/net/ipv4/tcp_synack_retries
5
```
tcp_synack_retries 的默认重试次数是 5 次，与客户端重传 SYN 类似，它的重传会经历 1、2、4、8、16 秒，最后一次重传后会继续等待 32 秒，如果服务端仍然没有收到 ACK，才会关闭连接，故共需要等待 63 秒。
服务器收到 ACK 后连接建立成功，此时，内核会把连接从`半连接队列`移除，然后创建新的完全的连接，并将其添加到 `accept 队列，`等待进程调用 accept 函数时把连接取出来。
如果进程不能及时地调用 accept 函数，就会造成 accept 队列（也称全连接队列）溢出，最终导致建立好的 TCP 连接被丢弃。

accept 队列已满，只能丢弃连接吗？
### 10.2.4 调整 tcp_abort_on_overflow 发送RST
丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。打开这一功能需要将 `tcp_abort_on_overflow` 参数设置为 1.

```shell
cat /proc/sys/net/ipv4/tcp_abort_on_overflow
0
```
`tcp_abort_on_overflow` 共有两个值分别是 0 和 1，其分别表示：

- 0 ：如果 accept 队列满了，那么 server 扔掉 client  发过来的 ack ；
- 1 ：如果 accept 队列满了，server 发送一个 RST 包给 client，表示废掉这个握手过程和这个连接；

如果要想知道客户端连接不上服务端，是不是服务端 TCP 全连接队列满的原因，那么可以把 `tcp_abort_on_overflow` 设置为 1，这时如果在客户端异常中可以看到很多 `connection reset by peer` 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。

通常情况下，应当把 `tcp_abort_on_overflow` 设置为 `0`，因为这样更有利于应对突发流量。
举个例子，当 accept 队列满导致服务器丢掉了 `ACK`，与此同时，客户端的连接状态却是 `ESTABLISHED`，客户端进程就在建立好的连接上发送请求。
只要服务器没有为请求回复 `ACK`，客户端的请求就会被多次**「重发」**。
如果服务器上的进程只是短暂的繁忙造成 `accept 队列满`，那么当 `accept 队列有空位`时，再次接收到的请求报文由于含有 `ACK`，仍然会触发服务器端成功建立连接。

所以，`tcp_abort_on_overflow` 设为 0 可以提高连接建立的成功率，
只有你非常肯定 TCP 全连接队列会长期溢出时，才能设置为 1 以尽快通知客户端。

### 10.2.5 调整 accept 队列的长度
accept 队列的长度取决于` somaxconn 和 backlog 之间的最小值`，也就是` min(somaxconn, backlog)`，其中：
`somaxconn `是 Linux 内核的参数，默认值是 128，可以通过 `net.core.somaxconn `来设置其值；
`backlog` 是` listen(int sockfd, int backlog) `函数中的 `backlog` 大小；
Tomcat、Nginx、Apache 常见的 Web 服务的 backlog 默认值都是 511。

> 如何查看服务端进程 accept 队列的长度？
可以通过` ss -ltn `命令查看：
```shell
-l 显示正在监听(listening)的socket
-n 不解析服务名称
-t 只显示tcpsocket
> ss -ltn
State       Recv-Q Send-Q                 Local Address:Port                                Peer Address:Port
LISTEN      0      128                     10.253.48.55:9966                                           *:*
LISTEN      0      128                                *:111                                            *:*
LISTEN      0      128                                *:80                                             *:*
LISTEN      0      5                      192.168.122.1:53                                             *:*
LISTEN      0      128                        127.0.0.1:33974                                          *:*
LISTEN      0      128                                *:22                                             *:*
LISTEN      0      128                        127.0.0.1:631                                            *:*
LISTEN      0      100                        127.0.0.1:25                                             *:*
LISTEN      0      128                        127.0.0.1:42267                                          *:*
LISTEN      0      128                                *:27017                                          *:*
LISTEN      0      128                             [::]:27018                                       [::]:*
LISTEN      0      128                             [::]:111                                         [::]:*
LISTEN      0      128                             [::]:8080                                        [::]:*
LISTEN      0      128                             [::]:22                                          [::]:*
LISTEN      0      128                            [::1]:631                                         [::]:*
LISTEN      0      128                             [::]:2233                                        [::]:*
LISTEN      0      100                            [::1]:25                                          [::]:*
LISTEN      0      128                             [::]:8090                                        [::]:*
```
- `Recv-Q`：`当前 accept 队列的大小`，也就是当前已完成三次握手并等待服务端 accept() 的 TCP 连接；
- `Send-Q`：`accept 队列最大长度`，上面的输出结果说明监听 80 端口的 TCP 服务，accept 队列的最大长度为 128；

> 查看由于 accept 连接队列已满，而被丢弃的连接？
> 当超过了 accept 连接队列，服务端则会丢掉后续进来的 TCP 连接，丢掉的 TCP 连接的个数会被统计起来，
> 我们可以使用 `netstat -s` 命令来查看：
```shell
> netstat -s | grep overflowed
xxx times the listen queue of a socket overflowed
```
上面看到的` xxx times` ，表示 `accept 队列溢出的次数`，注意这个是`累计值`。可以隔几秒钟执行下，如果这个数字一直在增加的话，说明 accept 连接队列偶尔满了。
如果持续不断地有连接因为 accept 队列溢出被丢弃，就应该`调大 backlog `以及`somaxconn `参数。

### 10.3 如何绕过三次握手？
以上我们只是在对三次握手的过程进行优化，接下来我们看看如何绕过三次握手发送数据。
三次握手建立连接造成的后果就是，HTTP 请求必须在一个 RTT（从客户端到服务器一个往返的时间）后才能发送。

在 Linux 3.7 内核版本之后，提供了 `TCP Fast Open` 功能，这个功能可以减少 TCP 连接建立的时延。

### 10.3.1 TCP Fast Open 功能的工作方式。
![ TCP Fast Open 功能](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZciat6yMSZJ2QYWIldpAXY6Vu6FONrqDCbf9aVRFWEnPWOTRhGolqOX1nia02pwjqM06wmrskNNGAPA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
#### 10.3.1.1 在客户端首次建立连接时的过程：

1. 客户端发送 `SYN` 报文，该报文包含 `Fast Open` 选项，且该选项的` Cookie 为空`，这表明客户端`请求 Fast Open Cookie`；
2. 支持 TCP Fast Open 的服务器`生成 Cookie`，并将其置于` SYN-ACK `数据包中的` Fast Open 选项`以发回客户端；
3. 客户端收到 `SYN-ACK` 后，本地缓存 Fast Open 选项中的 `Cookie`。

所以，第一次发起 HTTP GET 请求的时候，还是需要正常的三次握手流程。

#### 10.3.1.2 如果客户端再次向服务器建立连接时的过程：

1. 客户端发送 `SYN` 报文，该报文包含`「数据」`（对于非 TFO 的普通 TCP 握手过程，SYN 报文中不包含「数据」）以及此前记录的 `Cookie`；
2. 支持 TCP Fast Open 的服务器会对收到 `Cookie` 进行**校验**：
    如果 <u>Cookie 有效</u>，服务器将在 `SYN-ACK` 报文中对 `SYN 和「数据」`进行确认，服务器随后将「数据」递送至相应的应用程序；
    如果 <u>Cookie 无效</u>，服务器将丢弃 `SYN` 报文中包含的`「数据」`，且其随后发出的 `SYN-ACK` 报文将只确认 `SYN` 的对应序列号；
3. 如果服务器接受了 SYN 报文中的`「数据」`，服务器可在握手完成之前发送`「数据」`，**<font color="red">这就减少了握手带来的 1 个 RTT 的时间消耗；</font>**
4. 客户端将发送 ACK 确认服务器发回的 `SYN 以及「数据」`，但如果客户端在初始的 SYN 报文中发送的`「数据」没有被确认`，则客户端将`重新发送「数据」`；
5. 此后的 TCP 连接的数据传输过程和非 TFO 的正常情况一致。

注：客户端在请求并存储了 Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直至服务器认为 Cookie 无效（通常为过期）。

#### 10.3.1.3 Linux 下打开 TCP Fast Open 功能
设置` tcp_fastopen` 内核参数，来打开 Fast Open 功能：
```shell
cat /proc/sys/net/ipv4/tcp_fastopen
0
```
tcp_fastopn 各个值的意义:

- 0 关闭
- 1 作为客户端使用 Fast Open 功能
- 2 作为服务端使用 Fast Open 功能
- 3 无论作为客户端还是服务器，都可以使用 Fast Open 功能
TCP Fast Open 功能需要客户端和服务端同时支持，才有效果。

## 10.4 总结
### 10.4.0 优化三次握手

|        策略        |              TCP内核参数               |
| ------------------ | ------------------------------------- |
| SYN报文重传次数     | tcp_syn_retries                       |
| SYN半连接队列长度   | tcp_max_syn_backlog,somaxconn,backlog |
| SYN-ACK报文重传次数 | tcp_synack_retries                    |
| accpet 队列长度     | min(somaxconn,backlog)                |
| 绕过三次握手，TFO   | tcp_fastopen                          |

### 10.4.1 客户端的优化
当客户端发起 SYN 包时，可以通过 tcp_syn_retries 控制其重传的次数。

### 10.4.2 服务端的优化
1. 当服务端 SYN 半连接队列溢出后，会导致后续连接被丢弃，可以通过 `netstat -s` 观察半连接队列溢出的情况，如果 SYN 半连接队列溢出情况比较严重，可以通过` tcp_max_syn_backlog、somaxconn、backlog` 参数来调整 SYN 半连接队列的大小。
2. 服务端回复 SYN+ACK 的重传次数由 tcp_synack_retries 参数控制。如果遭受 SYN 攻击，应把 tcp_syncookies 参数设置为 1，表示仅在 SYN 队列满后开启 syncookie 功能，可以保证正常的连接成功建立。
3. 服务端收到客户端返回的 ACK，会把连接移入 accpet 队列，等待进行调用 accpet() 函数取出连接。
    可以通过 `ss -lnt` 查看服务端进程的 `accept 队列长度`，如果 accept 队列溢出，系统默认丢弃 ACK，如果可以把 `tcp_abort_on_overflow` 设置为 1 ，表示用 RST 通知客户端连接建立失败。
如果 accpet 队列溢出严重，可以通过 `listen` 函数的 `backlog 参数`和 `somaxconn 系统参数`提高队列大小，accept 队列长度取决于 `min(backlog, somaxconn)`。

### 10.4.3 绕过三次握手
`TCP Fast Open `功能可以绕过三次握手，使得 HTTP 请求减少了 1 个 RTT 的时间，Linux 下可以通过 `tcp_fastopen` 开启该功能，同时必须保证服务端和客户端同时支持。

# 十一、TCP 四次挥手的性能提升
### 11.0 FIN/ ACK ?
- `FIN` 就是结束连接的意思，谁发出 FIN 报文，就表示它将不会再发送任何数据，关闭这一方向上的传输通道；
- `ACK` 就是确认的意思，用来通知对方：你方的发送通道已经关闭；

### 11.1 TCP 四次挥手的性能提升:主动方的优化

关闭的连接的方式通常有两种，分别是 **RST 报文关闭**和 **FIN 报文关闭**。

- 如果进程异常退出了，内核就会发送 RST 报文来关闭，它可以不走四次挥手流程，是一个暴力关闭连接的方式。
- 安全关闭连接的方式必须通过`四次挥手`，它由进程调用 `close` 和 `shutdown` 函数发起 `FIN 报文`（shutdown 参数须传入 `SHUT_WR` 或者 `SHUT_RDWR` 才会发送 `FIN`）。

### 11.1.0 调用 close 函数 和 shutdown 函数有什么区别？

调用了 `close` 函数意味着`完全断开连接`，完全断开不仅指`无法传输`数据，而且也`不能发送`数据。
此时，调用了 `close` 函数的一方的连接叫做「**孤儿连接**」，如果你用` netstat -p` 命令，会发现连接对应的进程名为空。
使用 close 函数关闭连接是不优雅的。

于是，就出现了一种优雅关闭连接的 `shutdown` 函数，它可以控制只关闭一个方向的连接：
```c
int shutdown(int sock, int howto);
```
第二个参数决定断开连接的方式，主要有以下三种方式：
- `SHUT_RD(0)`：关闭连接的「**读**」这个方向，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收到新的数据，会对数据进行 ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。
- `SHUT_WR(1)`：关闭连接的「**写**」这个方向，这就是常被称为**「半关闭」**的连接。如果发送缓冲区还有未发送的数据，将被立即发送出去，并发送一个 FIN 报文给对端。
- `SHUT_RDWR(2)`：相当于 `SHUT_RD` 和 `SHUT_WR` 操作各一次，关闭套接字的读和写两个方向。

close 和 shutdown 函数都可以关闭连接，但这两种方式关闭的连接，不只功能上有差异，控制它们的 Linux 参数也不相同。

### 11.1.1 FIN_WAIT1 状态的优化

#### 11.1.1.1 重发 FIN 报文次数 tcp_orphan_retries
主动方发送 FIN 报文后，连接就处于 `FIN_WAIT1` 状态，正常情况下，如果能及时收到被动方的 `ACK`，则会很快变为 `FIN_WAIT2` 状态。
但是当迟迟收不到对方返回的 `ACK` 时，连接就会一直处于 `FIN_WAIT1` 状态。
此时，内核会定时`重发 FIN 报文`，其中重发次数由 `tcp_orphan_retries` 参数控制
（注意，orphan 虽然是孤儿的意思，该参数却不只对孤儿连接有效，事实上，它对所有 `FIN_WAIT1` 状态下的连接都有效），默认值是 `0`。
```shell
$ cat  /proc/sys/net/ipv4/tcp_orphan_retries
0
$ echo 5 >  /proc/sys/net/ipv4/tcp_orphan_retries
# 调整 FIN报文 重发次数为5次，默认0次，（为0时特指8次）
```

如果 FIN_WAIT1 状态连接很多，我们就需要考虑降低 `tcp_orphan_retries` 的值，当重传次数超过 `tcp_orphan_retries` 时，连接就会直接关闭掉。


对于普遍正常情况时，调低 `tcp_orphan_retries` 就已经可以了。
如果遇到恶意攻击，FIN 报文根本无法发送出去，这由 TCP 两个特性导致的：

1. 首先，TCP 必须保证报文是`有序`发送的，FIN 报文也不例外，当发送`缓冲区还有数据`没有发送时，FIN 报文也`不能提前发送`。
2. 其次，TCP 有`流量控制`功能，当接收方`接收窗口为 0` 时，发送方就`不能再发送`数据。所以，当攻击者下载大文件时，就可以通过接收窗口`设为 0` ，这就会使得` FIN 报文都无法发送出去`，那么连接会一直处于 `FIN_WAIT1` 状态。

#### 11.1.1.2 孤儿连接 的最大数量 tcp_max_orphans
解决这种问题的方法，是调整 `tcp_max_orphans` 参数，它定义了「孤儿连接」的最大数量：
```shell
$ cat /proc/sys/net/ipv4/tcp_max_orphans
65536
$ echo 16384 > /proc/sys/net/ipv4/tcp_max_orphans
```
当进程调用了 close 函数关闭连接，此时连接就会是「孤儿连接」，因为它无法在发送和接收数据。
Linux 系统为了`防止孤儿连接过多`，导致系统资源长时间被占用，就提供了 `tcp_max_orphans` 参数。
如果孤儿连接数量大于它，新增的孤儿连接将`不再走四次挥手`，而是直接发送 `RST 复位报文强制关闭`。

### 11.1.2 FIN_WAIT2 状态的优化

当主动方收到 **ACK** 报文后，会处于 `FIN_WAIT2` 状态，就表示主动方的发送通道已经关闭，接下来将等待`对方`发送 `FIN` 报文，关闭对方的发送通道。

- 这时，如果连接是用 `shutdown` 函数关闭的，连接可以一直处于 `FIN_WAIT2` 状态，因为它可能还可以发送或接收数据。
- 但对于 `close` 函数关闭的孤儿连接，由于无法在发送和接收数据，所以这个状态不可以持续太久，而 `tcp_fin_timeout` 控制了这个状态下连接的持续时长，默认值是 60 秒：
```shell
$ cat /proc/sys/net/ipv4/tcp_fin_timeout
60
```
它意味着对于**孤儿连接**（`调用 close 关闭的连接`），如果在 60 秒后还没有收到 FIN 报文，连接就会`直接关闭`。
这个 60 秒不是随便决定的，它与 `TIME_WAIT` 状态持续的时间是相同的，后面我们在来说说为什么是 60 秒。

### 11.1.3 TIME_WAIT 状态的优化
`TIME_WAIT` 是主动方四次挥手的最后一个状态，也是最常遇见的状态。
当收到被动方发来的 `FIN` 报文后，主动方会立刻回复 `ACK`，表示确认对方的发送通道已经关闭，接着就处于 `TIME_WAIT` 状态。
在 Linux 系统，TIME_WAIT 状态会持续 60 秒后才会进入关闭状态。
`TIME_WAIT` 状态的连接，在主动方看来确实快已经关闭了。
然后，被动方没有收到 ACK 报文前，还是处于 `LAST_ACK` 状态。
如果这个 ACK 报文没有到达被动方，被动方就会`重发 FIN 报文`。
重发次数仍然由前面介绍过的 `tcp_orphan_retries` 参数控制。

TIME-WAIT 的状态尤其重要，主要是两个原因：

1. 防止具有相同「四元组」的「旧」数据包被收到；
2. 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；

#### 11.1.3.1 TIME_WAIT 原因一：防止旧连接的数据包
TIME-WAIT 的一个作用是防止收到历史数据，从而导致数据错乱的问题。
假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？
![接收到历史数据的异常](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZciat6yMSZJ2QYWIldpAXY6Veuzbfy6pZQNiavDH6ue03MC0Ij0euZ97yLQSwUCJywbrYibWyGqxckDA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
如上图黄色框框服务端在关闭连接之前发送的 `SEQ = 301` 报文，被网络延迟了。
这时有相同端口的 TCP 连接被复用后，被延迟的 `SEQ = 301` 抵达了客户端，那么客户端是有可能正常接收这个过期的报文，这就会产生数据错乱等严重的问题。

所以，TCP 就设计出了这么一个机制，经过 **`2MSL`** 这个时间，足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。

#### 11.1.3.2 TIME_WAIT 原因二：保证连接正确关闭

TIME-WAIT 的另外一个作用是等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。
假设 TIME-WAIT 没有等待时间或时间过短，断开连接会造成什么问题呢？

![没有确保正常断开的异常](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZciat6yMSZJ2QYWIldpAXY6Voo03UXicFjeywGE5DEsPBMugJwW8bgqKDMbqoygVTd7nVRArvCQKAAQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
如上图红色框框客户端四次挥手的最后一个 ACK 报文如果在网络中被丢失了，此时如果客户端 `TIME-WAIT` 过短或没有，则就直接进入了 CLOSE 状态了，那么服务端则会一直处在 `LAST-ACK` 状态。
当客户端发起建立连接的 `SYN `请求报文后，服务端会发送 `RST 报文`给客户端，连接建立的过程就会被终止。

#### 11.1.3.3 为什么 TIME_WAIT 状态要保持 60 秒呢？
这与孤儿连接 `FIN_WAIT2` 状态默认保留 60 秒的原理是一样的，因为这两个状态都需要保持 `2MSL` 时长。
MSL 全称是 `Maximum Segment Lifetime`，它定义了一个报文在网络中的最长生存时间
（报文每经过一次路由器的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报文就被丢弃，这就限制了报文的最长存活时间）。

为什么是 2 MSL 的时长呢？
这其实是相当于至少允许报文丢失一次。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

为什么不是 4 或者 8 MSL 的时长呢？
你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。

因此，`TIME_WAIT` 和 `FIN_WAIT2` 状态的最大时长都是 `2 MSL`，
由于在 Linux 系统中，MSL 的值固定为 30 秒，所以它们都是 60 秒。

#### 11.1.3.4 TIME_WAIT过多的危害
虽然 TIME_WAIT 状态有存在的必要，但它毕竟会消耗系统资源。如果发起连接一方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。

**客户端受端口资源限制：**
如果客户端 `TIME_WAIT` 过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致`无法创建新的连接`；

**服务端受系统资源限制：**
由于一个 四元组表示TCP连接，理论上服务端可以建立很多连接，服务端确实只监听一个端口 但是会把连接扔给处理线程，所以理论上监听的端口可以继续监听。
但是线程池处理不了那么多一直不断的连接了。所以当服务端出现大量 `TIME_WAIT` 时，系统资源被占满时，会导致`处理不过来新的连接`；

#### 11.1.3.5 tcp_max_tw_buckets参数 TIME_WAIT最大值，大于时直接关闭
Linux 提供了 `tcp_max_tw_buckets` 参数，当 `TIME_WAIT` 的连接数量超过该参数时，新关闭的连接就不再经历 `TIME_WAIT` 而直接关闭
```shell
$ cat /proc/sys/net/ipv4/tcp_max_tw_buckets
65536
```
当服务器的并发连接增多时，相应地，同时处于 `TIME_WAIT` 状态的连接数量也会变多，此时就应当调大 `tcp_max_tw_buckets` 参数，减少不同连接间数据错乱的概率。
`tcp_max_tw_buckets` 也不是越大越好，毕竟内存和端口都是有限的。

#### 11.1.3.6 tcp_tw_reuse参数复用`TIME_WAIT` 状态的连接
有一种方式可以在建立新连接时，复用处于 `TIME_WAIT` 状态的连接，那就是打开 `tcp_tw_reuse` 参数。
但是需要注意，该参数是只用于客户端（建立连接的发起方），因为是在调用 `connect()` 时起作用的，而对于服务端（被动连接方）是没有用的。
```shell
# 默认关闭，打开置为1
$ cat /proc/sys/net/ipv4/tcp_tw_reuse
0
```
`tcp_tw_reuse` 从协议角度理解是安全可控的，可以复用处于 `TIME_WAIT` 的端口为新的连接所用。
什么是协议角度理解的安全可控呢？主要有两点：

1. 只适用于连接发起方，也就是 C/S 模型中的客户端；
2. 对应的 `TIME_WAIT` 状态的连接创建时间超过 1 秒才可以被复用。
使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持（对方也要打开 ）：
```shell
# 默认打开，为1
$ cat /proc/sys/net/ipv4/tcp_timestamps
1
```
由于引入了时间戳，它能带来了些好处：
我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃；
同时，它还可以防止序列号绕回，也是因为重复的数据包会由于时间戳过期被自然丢弃；

> 老版本：
> 老版本的 Linux 还提供了 `tcp_tw_recycle` 参数，但是当开启了它，就有两个坑：
> 1. Linux 会加快客户端和服务端 TIME_WAIT 状态的时间，也就是它会使得 `TIME_WAIT` 状态会小于 60 秒，很容易导致数据错乱；
> 2. 另外，Linux 会丢弃所有来自远端时间戳小于上次记录的时间戳（由同一个远端发送的）的任何数据包。就是说要使用该选项，则必须保证数据包的时间戳是单调递增的。
>    那么，问题在于，此处的时间戳并不是我们通常意义上面的绝对时间，而是一个相对时间。很多情况下，我们是没法保证时间戳单调递增的，比如使用了 NAT，LVS 等情况；
> 所以，不建议设置为 1 ，建议关闭它：
> ```shell
> # 默认关闭，为0
> $ cat /proc/sys/net/ipv4/tcp_tw_recycle
> 0
> ```
> 在 Linux 4.12 版本后，Linux 内核直接取消了这一参数。
#### 11.1.3.7 socket选项

```c
shutdown(fd, SHUT_RDWR);

struct linger linger;
linger.l_onoff = 1;
linger.l_linger = 0;
setsockopt(fd, SOL_SOCKET, SO_LINGER, (char *) &linger, sizeof(linger));
close(fd);

# SO_LINGER选项用来改变此缺省设置。使用如下结构：
struct linger {
     int l_onoff; /* 0 = off, nozero = on */
     int l_linger; /* linger time */
};
```
有下列三种情况：

1. 设置 `l_onoff`为   0，
    则该选项关闭，`l_linger`的值被忽略，等于内核缺省情况，close调用会立即返回给调用者，如果可能将会`传输任何未发送的数据`；
2. 设置 `l_onoff`为非0，`l_linger`为0，
    则套接口关闭时TCP夭折连接，TCP将`丢弃保留在套接口发送缓冲区中的任何数据`并`发送一个RST`给对方，而不是通常的四分组终止序列，这`避免了TIME_WAIT状态`；
3. 设置 `l_onoff`为非0，`l_linger`为非0，
    当套接口关闭时内核将拖延一段时间（由`l_linger`决定）。
    如果套接口缓冲区中仍残留数据，进程将处于睡眠状态，直 到
    （a）所有数据发送完且被对方确认，之后进行正常的终止序列（描述字访问计数为0）或
    （b）延迟时间到。此种情况下，应用程序检查close的返回值是非常重要的，如果在数据发送完并被确认前时间到，close将返回`EWOULDBLOCK`错误且套接口发送缓冲区中的任何数据都丢失。
    close的成功返回仅告诉我们发送的数据（和`FIN`）已由对方TCP确认，它并不能告诉我们对方应用进程是否已读了数据。如果套接口设为非阻塞的，它将不等待close完成。

另外，我们可以在程序中设置 `socket 选项`，来设置调用 `close `关闭连接行为。
如果`l_onoff`为非 0， 且`l_linger`值为 0，那么调用`close`后，会立该发送一个` RST `标志给对端，该 TCP 连接将`跳过四次挥手`，也就跳过了` TIME_WAIT `状态，`直接关闭`。
但这为跨越 `TIME_WAIT `状态提供了一个可能，不过是一个非常`危险`的行为，不值得提倡。

## 11.2 被动方的优化
### 11.2.1 被动方状态转换CLOSE_WAIT、LAST_ACK
当被动方收到 `FIN` 报文时，内核会自动回复 `ACK`，同时连接处于 `CLOSE_WAIT` 状态，顾名思义，它表示等待应用进程调用 `close` 函数关闭连接。
内核没有权利替代进程去关闭连接，因为如果主动方是通过 `shutdown` 关闭连接，那么它就是想在`半关闭连接`上接收数据或发送数据。因此，Linux 并没有限制 `CLOSE_WAIT` 状态的持续时间。

当然，大多数应用程序并不使用 `shutdown` 函数关闭连接。所以，当你用 `netstat` 命令发现大量 `CLOSE_WAIT` 状态，就需要排查你的应用程序，因为可能因为应用程序出现了 Bug，read 函数返回 0 时，没有调用 `close` 函数。

处于 `CLOSE_WAIT` 状态时，调用了 `close` 函数，内核就会发出 `FIN` 报文关闭发送通道，同时连接进入 `LAST_ACK` 状态，等待主动方返回 `ACK` 来确认连接关闭。
如果迟迟收不到这个 `ACK`，内核就会重发 `FIN` 报文，重发次数仍然由 `tcp_orphan_retries`参数控制，这与主动方重发 `FIN` 报文的优化策略一致。

还有一点我们需要注意的，如果被动方迅速调用 `close` 函数，那么被动方的 `ACK` 和 `FIN` 有可能在一个报文中发送，这样看起来，四次挥手会变成三次挥手，这只是一种特殊情况，不用在意。

### 11.2.2 如果连接双方同时关闭连接，会怎么样？都进入FIN_WAIT_1

由于 TCP 是双全工的协议，所以是会出现两方同时关闭连接的现象，也就是同时发送了 FIN 报文。
此时，上面介绍的优化策略仍然适用。两方发送 FIN 报文时，都认为自己是主动方，所以都进入了 `FIN_WAIT1` 状态，`FIN` 报文的重发次数仍由 `tcp_orphan_retries` 参数控制。

![双方同时关闭](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZciat6yMSZJ2QYWIldpAXY6VwnRFnFribrznkfDy3FiaerLG59wIR72ZxL2w3ntkSQEsUW9quibiabQksQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
双方在等待 `ACK` 报文的过程中，都等来了 `FIN` 报文。
这是一种新情况，所以连接会进入一种叫做 `CLOSING` 的新状态，它替代了 `FIN_WAIT2` 状态。
接着，双方内核回复 `ACK` 确认对方发送通道的关闭后，进入 `TIME_WAIT` 状态，等待 `2MSL` 的时间后，连接自动关闭。

## 11.3 总结
### 11.3.0 优化四次挥手
需要根据主动方和被动方四次挥手状态变化来调整系统 TCP 内核参数。

|                 策略                 |         TCP内核参数          |
| ------------------------------------ | --------------------------- |
| FIN报文重传次数                       | tcp_orphan_retries          |
| FIN_WAIT2状态时间(适用close关闭的连接) | tcp_fin_timeout             |
| 孤儿连接上限个数(适用close关闭的连接)   | tcp_max_orphans             |
| TIME_WAIT个数上限                    | tcp_max_tw_buckets          |
| 复用TIME_WAIT状态连接(只适用客户端)    | tcp_tw_reuse,tcp_timestamps |

### 11.3.1 主动方的优化

主动发起 FIN 报文断开连接的一方，如果迟迟没收到对方的 `ACK` 回复，则会重传 `FIN` 报文，重传的次数由 `tcp_orphan_retries` 参数决定。

当主动方收到 `ACK` 报文后，连接就进入 `FIN_WAIT2` 状态，根据关闭的方式不同，优化的方式也不同：

1. 如果这是 `close` 函数关闭的连接，那么它就是`孤儿连接`。如果 `tcp_fin_timeout` 秒内没有收到对方的 `FIN` 报文，连接就直接关闭。同时，为了应对孤儿连接占用太多的资源，`tcp_max_orphans` 定义了最大孤儿连接的数量，超过时连接就会直接释放。
2. 反之是 `shutdown` 函数关闭的连接，则不受此参数限制；

当主动方接收到 `FIN` 报文，并返回 `ACK` 后，主动方的连接进入 `TIME_WAIT` 状态。这一状态会持续 1 分钟，为了防止 `TIME_WAIT` 状态占用太多的资源，`tcp_max_tw_buckets` 定义了最大数量，超过时连接也会直接释放。

当 `TIME_WAIT` 状态过多时，还可以通过设置 `tcp_tw_reuse` 和 `tcp_timestamps` 为 1 ，将 `TIME_WAIT` 状态的端口`复用`于作为客户端的新连接，注意该参数只适用于`客户端`。

### 11.3.2 被动方的优化

被动关闭的连接方应对非常简单，它在回复 `ACK` 后就进入了 `CLOSE_WAIT` 状态，等待进程调用 `close` 函数关闭连接。
因此，出现大量 `CLOSE_WAIT` 状态的连接时，应当从应用程序中找问题。

当被动方发送 `FIN` 报文后，连接就进入 `LAST_ACK` 状态，在未等到 `ACK` 时，会在 `tcp_orphan_retries` 参数的控制下重发 FIN 报文。

# 十二、传输
## 12.1 传输方式
除了流式传输之外，还有其他几种数据传输方式，这些方式适用于不同的应用场景。下面是一些常见的数据传输方式及其特点：

### 12.1.1. 文件传输（File Transfer）

- **特点**：
  - 数据一次性传输完成，用户需要等待整个文件传输完毕才能使用。
  - 适用于传输较大的文件，如文档、图片、视频等。
  - 通常不支持断点续传功能。

- **协议**：
  - **FTP (File Transfer Protocol)**：传统的文件传输协议，支持文件上传和下载。
  - **SFTP (SSH File Transfer Protocol)**：基于SSH协议的安全文件传输协议。
  - **SCP (Secure Copy Protocol)**：一种简单的文件传输协议，也基于SSH。

### 12.1.2. 分布式文件系统 (Distributed File Systems)

- **特点**：
  - 分布式文件系统允许多个节点共同存储和管理文件。
  - 数据可以分布在网络中的多个节点上，提高可靠性和性能。
  - 适用于大型文件系统和大规模数据处理。

- **示例**：
  - **HDFS (Hadoop Distributed File System)**：用于大数据处理的分布式文件系统。
  - **GlusterFS**：开源的分布式文件系统，支持横向扩展。

### 12.1.3. 对象存储 (Object Storage)

- **特点**：
  - 对象存储是一种非结构化的数据存储方式，每个对象都由数据和元数据组成。
  - 适用于存储大量的非结构化数据，如图像、视频、文档等。
  - 提供高度可扩展性和容错性。

- **示例**：
  - **Amazon S3 (Simple Storage Service)**：亚马逊提供的云存储服务。
  - **Google Cloud Storage**：谷歌提供的云存储服务。

### 12.1.4. 块存储 (Block Storage)

- **特点**：
  - 块存储提供直接访问存储设备的能力，就像挂载了一个硬盘。
  - 适用于需要高性能和低延迟的应用场景，如数据库服务器。
  - 数据按固定大小的块进行存储和传输。

- **示例**：
  - **iSCSI (Internet Small Computer System Interface)**：基于IP网络的块存储协议。
  - **NFS (Network File System)**：虽然主要用于文件共享，但也可以用于块存储。

### 12.1.5. 消息队列 (Message Queues)

- **特点**：
  - 消息队列用于异步通信，可以将消息存储在队列中，供消费者按需处理。
  - 适用于需要解耦生产者和消费者的应用场景。
  - 支持消息的可靠传输和处理。

- **示例**：
  - **AMQP (Advanced Message Queuing Protocol)**：一种开放标准的消息队列协议。
  - **RabbitMQ**：基于AMQP的开源消息代理软件。
  - **Kafka**：一个分布式流处理平台，可以作为消息队列使用。

### 12.1.6. 数据库复制 (Database Replication)

- **特点**：
  - 数据库复制允许将数据从一个数据库（主数据库）复制到另一个或多个数据库（从数据库）。
  - 适用于提高数据可用性和冗余度。
  - 可以实现读写分离，提高性能。

- **示例**：
  - **MySQL Master-Slave Replication**：MySQL提供的复制功能。
  - **MongoDB Replication**：MongoDB提供的复制功能。

### 12.1.7 总结

每种传输方式都有其适用的场景和特点。选择合适的传输方式取决于具体的应用需求、数据类型、网络环境等因素。例如，文件传输适用于大文件的一次性传输，而流式传输适用于实时数据的逐步传输。在设计系统时，根据不同的应用场景选择合适的传输方式是非常重要的。

流式传输（Streaming）是一种数据传输技术，它允许数据在传输过程中被逐步处理，而不是等待整个数据包传输完成后再进行处理。流式传输主要用于实时传输音频、视频等多媒体内容，以及实时数据处理的应用场景。
# 12.2 流式传输
### 12.2.1 流式传输的特点

1. **实时性**：
   - 流式传输可以实现实时播放或处理，用户可以在数据传输的同时开始观看或处理数据。
   - 例如，在流媒体服务中，用户可以开始观看视频，而视频的剩余部分仍在后台继续加载。

2. **渐进式传输**：
   - 数据以连续的方式传输，用户可以逐步接收数据，而不需要等待整个文件传输完成。
   - 这种方式减少了等待时间，提高了用户体验。

3. **适应性**：
   - 流式传输可以根据网络状况自动调整传输速率和质量，以提供最佳的用户体验。
   - 例如，视频流可以根据网络带宽动态调整分辨率和码率。

4. **断点续传**：
   - 支持断点续传功能，即如果传输中断，可以从上次中断的地方继续传输，而不是从头开始。
   - 这对于长时段的传输非常有用，可以避免重新开始传输整个文件。

5. **数据缓存**：
   - 流式传输通常会在接收端缓存一部分数据，以保证播放或处理的流畅性。
   - 这样的缓存机制有助于平滑网络波动的影响。

### 12.2.2 流式传输的应用

1. **视频流媒体**：
   - 在线视频平台（如Netflix、YouTube）使用流式传输来提供视频内容。
   - 视频内容被分成多个小片段，每个片段被依次加载并播放。

2. **音频流媒体**：
   - 音乐流媒体服务（如Spotify、Apple Music）使用流式传输来提供音乐内容。
   - 音乐文件被连续传输，用户可以边听边下载。

3. **实时数据分析**：
   - 在大数据处理和实时分析领域，流式传输用于处理连续的数据流，例如传感器数据、社交媒体数据等。
   - 这些数据流可以被实时分析和处理，以提供即时反馈或洞察。

4. **直播**：
   - 直播服务使用流式传输来实时传输视频和音频数据。
   - 用户可以观看直播内容，而数据在后台持续传输。

### 12.2.3 技术实现

1. **HTTP Live Streaming (HLS)**：
   - 一种基于HTTP的流式传输协议，用于实时传输音视频内容。
   - HLS将内容分割成一系列短小的文件段，并通过HTTP进行传输。

2. **Dynamic Adaptive Streaming over HTTP (DASH)**：
   - 一种自适应流式传输协议，可以根据网络条件动态调整视频质量。
   - DASH支持多种编码格式和码率，以提供最佳的用户体验。

3. **Real-Time Messaging Protocol (RTMP)**：
   - 一种专为实时音视频传输设计的协议，通常用于直播服务。
   - RTMP支持低延迟传输，适合需要实时互动的应用场景。

4. **WebRTC**：
   - 一种用于实现实时通信的技术，支持视频通话、屏幕共享等功能。
   - WebRTC通过点对点连接直接传输数据，不需要通过服务器中转。

流式传输技术极大地改变了我们消费多媒体内容的方式，使得我们可以享受高质量的实时内容，而无需等待长时间的下载。随着网络技术和编解码技术的进步，流式传输的应用领域还在不断扩大。
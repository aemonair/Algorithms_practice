[TOC]
# 一、概念
## 1.1. 进程
### 1.1.0 进程概念
> 运行中的程序，就被称为「进程」
- 进程是程序执行时的一个实例，是系统进行**资源分配的基本单位**。
  * 所有与该进程有关的资源，都被记录在进程控制块(PCB)中。以表示该进程拥有这些资源或正在使用它们。
  * 另外，进程也是抢占处理机的调度单位，它拥有一个完整的虚拟地址空间。当进程发生调度时，不同的进程拥有不同的虚拟地址空间，而同一进程内的不同线程共享同一地址空间。
```cpp
  struct task_struct {
    // 进程状态
    long              state;
    // 虚拟内存结构体
    struct mm_struct  *mm;
    // 进程号
    pid_t             pid;
    // 指向父进程的指针
    struct task_struct   *parent;
    // 子进程列表
    struct list_head      children;
    // 存放文件系统信息的指针
    struct fs_struct      *fs;
    // 一个数组，包含该进程打开的文件指针
    struct files_struct   *files;
};
```
#### 1.1.1 files文件描述符
0 是输入，1 是输出，2 是错误。

### 1.1.2 进程执行
程序是指令、数据及其组织形式的描述，进程是程序的实体。程序本身是没有生命周期的，它只是存在磁盘上的一些指令,程序一旦运行就是进程。
当程序需要运行时，操作系统将代码和所有静态数据记载到内存和进程的地址空间（每个进程都拥有唯一的地址空间，见下图所示）中，
通过创建和初始化栈（局部变量，函数参数和返回地址)、
分配堆内存以及与IO相关的任务，
当前期准备工作完成，
启动程序，OS将CPU的控制权转移到新创建的进程，
进程开始运行。

### 1.1.3 PCB
操作系统对进程的控制和管理通过`PCB(Processing Control Block)`，PCB通常是系统内存占用区中的一个连续存区，
它存放着操作系统用于描述进程情况及控制进程运行所需的全部信息(进程标识号,进程状态,进程优先级,文件系统指针以及各个寄存器的内容等)，
进程的PCB是系统感知进程的唯一实体。

#### 1.1.3.1 <span style="color:red;">进程描述信息</span>：
- 进程标识符`pid_t pid;`：标识各个进程，每个进程都有一个并且唯一的标识符；
- 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；

#### 1.1.3.2 <span style="color:red;">进程控制和管理信息</span>：
- 进程当前状态`long state;`，如 new、ready、running、waiting 或 blocked 等；
- 进程优先级：进程抢占 CPU 时的优先级；

#### 1.1.3.3 <span style="color:red;">资源分配清单</span>：
- 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。
`struct files_struct   *files;`

#### 1.1.3.4 <span style="color:red;">CPU 相关信息</span>：
- CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。

### 1.1.3. 每个 PCB 是如何组织的呢？
通常是通过`链表`的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。(阻塞队列/就绪队列)
除了链接的组织方式，还有`索引`方式，它的工作原理：将同一状态的进程组织在一个`索引表`中，索引表项指向相应的 PCB，不同状态对应不同的索引表。
一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。

### 1.1.4 进程执行状态
一个进程至少具有5种基本状态：
 初始态、执行状态、等待（阻塞）状态、就绪状态、终止状态

#### 1.1.4.1 初始状态：
-  进程刚被创建，由于其他进程正占有CPU所以得不到执行，只能处于初始状态。
#### 1.1.4.2 **执行状态Running**：
- 任意时刻处于执行状态的进程只能有一个。该时刻进程占用 CPU。
#### 1.1.4.3 **就绪状态Ready**：
- 只有处于就绪状态的经过调度才能到执行状态。可运行，但因为其他进程正在运行而暂停停止；
#### 1.1.4.4 **等待阻塞状态Blocked**：
- 进程等待某件事件完成，阻塞。该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；
#### 1.1.4.5 停止结束状态Exit：
- 进程结束，进程正在从系统中消失时的状态；

#### 1.1.4.6 状态变迁：
`NULL     -> 创建状态`：一个新进程被创建时的第一个状态；
`创建状态 -> 就绪状态`：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；
`就绪状态 -> 运行状态`：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；
`运行状态 -> 结束状态`：当进程已经运行完成或出错时，会被操作系统作结束状态处理；
`运行状态 -> 就绪状态`：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；
`运行状态 -> 阻塞状态`：当进程请求某个事件且必须等待时，例如请求 I/O 事件；
`阻塞状态 -> 就绪状态`：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；

#### 1.1.4.6 挂起
还有一个状态叫挂起状态，它表示进程没有占有内存空间。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。
挂起状态可以分为两种：

- 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
- 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；
这两种挂起状态加上前面的五种状态，就变成了七种状态变迁，
![进程七种状态变迁
](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcvw4t9kicec370n3cvX2JS9OSw0O4hBZhsvyrPTCkXqwCg9QgtBfdrCsU90NaspiabyILN5QxmAYxQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)

### 1.1.5 进程切换
操作系统对把CPU控制权在不同进程之间交换执行的机制成为<span style="color:red;">`上下文切换`（context switch）</span>，
即保存当前进程的上下文，恢复新进程的上下文，然后将CPU控制权转移到新进程，新进程就会从上次停止的地方开始。
因此，进程是轮流使用CPU的，CPU被若干进程共享，使用某种调度算法来决定何时停止一个进程，并转而为另一个进程提供服务
-单核CPU双进程的情况 ：

 - 进程直接特定的机制和遇到I/O中断的情况下，进行上下文切换，轮流使用CPU资源
- 双核CPU双进程的情况 ：
 - 每一个进程独占一个CPU核心资源，在处理I/O请求的时候，CPU处于阻塞状态

### 1.1.6 虚拟存储 进程间数据共享
系统提供了一种对主存的抽象概念，即为虚拟存储器（VM）。
虚拟存储（Virtual Memory） 是一种内存管理技术，它是一个抽象的概念，它为每一个进程提供了一个假象，即每个进程都在独占地使用主存。
它使得每个进程都认为自己在使用全部的（或大部分的）物理内存，但实际上，进程所使用的内存可能只是物理内存的一小部分，甚至可能被交换出到磁盘上。
虚拟存储系统允许我们把物理内存看作是内存池的一个缓存（cache），它缓存的是在磁盘上存储的数据和代码。每个进程有自己的虚拟地址空间，这个地址空间被分割成多个固定大小的区块，称为页面（page）。对应地，物理内存也被分割成同样大小的区块，称为页框（page frame）。
虚拟存储器主要提供了三个能力：

- 将主存看成是一个存储在磁盘上的<font color='red'>高速缓存</font>，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，更高效地使用主存
- 为每个进程提供了一致的地址空间，从而<font color='red'>简化了存储器管理</font>
- 保护了每个进程的地址空间<font color='red'>不被其他进程破坏</font>
> 由于进程拥有自己独占的虚拟地址空间，CPU通过地址翻译将虚拟地址转换成真实的物理地址，每个进程只能访问自己的地址空间。
> 因此，在没有其他机制（进程间通信）的辅助下，进程之间是无法共享数据的

在虚拟存储系统中，进程间数据共享通常是通过映射同一块物理内存到不同进程的虚拟地址空间来实现的。例如，在Unix系统中，可以使用mmap系统调用创建一块共享内存区域。

进程间数据共享（Inter-Process Communication, IPC） 是操作系统提供的一种机制，使得在运行在同一台机器上的不同进程可以相互交换数据。IPC机制有多种实现方式，包括管道（pipe），消息队列（message queue），信号（signal），共享内存（shared memory）等。
## 1.2. 线程
### 1.2.0 线程
-  线程，有时也被称为轻量级进程，是程序执行流的最小单元，是进程中的一个实体，是被**系统独立调度和分派的基本单位**。
  * 与进程不同，线程与资源分配无关，线程自己不拥有系统资源，它属于某一个进程，并与进程内的其他线程一起共享进程的资源。
  * 线程只由相关堆栈（系统栈或用户栈）寄存器和线程控制表TCB组成。

一个进程可以有一个或多个线程，
同一进程中的多个线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。
但同一进程中的多个线程有各自的调用栈和线程本地存储。

### 1.2.1 TCB线程控制块
系统利用PCB来完成对进程的控制和管理。
同样，系统为线程分配一个线程控制块TCB（Thread Control Block）,将所有用于控制和管理线程的信息记录在线程的控制块中，
TCB中通常包括：

- 线程标志符
- 一组寄存器
- 线程运行状态
- 优先级
- 线程专有存储区
- 信号屏蔽

fork创建进程，pthread创建线程
但无论线程还是进程，都是用task_struct结构表示的，唯一的区别就是共享的数据区域不同。
线程共享 虚拟内存、文件描述符；
mm指向的是进程的虚拟内存，也就是载入资源和可执行文件的地方；files指针指向一个数组，这个数组里装着所有该进程打开的文件的指针。

## 1.3. 进程和线程的关系
### 1.3.0 进程和线程的关系
- 通常在一个进程中可以包含若干个线程，它们可以利用进程所拥有的资源。
- 但是，一个线程只属于一个进程。进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。而且需要注意的是，线程不是一个可执行的实体。
### 1.4.0 进程和线程的比较
#### 1.4.1 调度 ：
在引入线程的操作系统中，线程是调度和分配的基本单位 ，进程是资源拥有的基本单位 。
把传统进程的两个属性分开，线程便能轻装运行，从而可 显著地提高系统的并发程度 。
在同一进程中，线程的切换不会引起进程的切换；在由一个进程中的线程切换到另一个进程中的线程时，才会引起进程的切换。

#### 1.4.2 并发性 ：
在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行，因而使操作系统具有更好的并发性，从而能 更有效地使用系统资源和提高系统吞吐量。
#### 1.4.3 拥有资源 ：
不论是传统的操作系统，还是设有线程的操作系统，进程都是拥有资源的一个独立 单位，它可以拥有自己的资源。一般地说，线程自己不拥有系统资源（只有一些必不可少的资源，但它可以访问其隶属进程的资源。
#### 1.4.4 系统开销：
由于在创建或撤消进程时，系统都要为之分配或回收资源，因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。进程切换的开销也远大于线程切换的开销。
由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。
#### 1.4.5 通信：
由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。
进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性，因此共享简单。但是线程的数据同步要比进程略复杂。
#### 1.4.6 创建及调试
进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂
#### 1.4.7 互相影响
进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉
#### 1.4.8 多核
进程适应于多核、多机分布；线程适用于多核



### 1.5.0 进程和线程区别？
1. 进程是资源分配的基本单位，线程是cpu调度，或者说是程序执行的最小单位。但是并不是说CPU不在以进程为单位进行调度，虽然在某些操作系统中是这样。同一个进程中并行运行多个线程，就是对在同一台计算机上运行多个进程的模拟。
2. 进程有独立的地址空间，而同一进程中的线程共享该进程的地址空间。比如在linux下面启动一个新的进程，系统必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种非常昂贵的多任务工作方式。而运行一个进程中的线程，它们之间共享大部分数据，使用相同的地址空间，因此启动一个线程，切换一个线程远比进程操作要快，花费也要小得多。当然，线程是拥有自己的寄存器和堆栈（线程栈），比如在windows中用_beginthreadex创建一个新进程就会在调用CreateThread的同时申请一个专属于线程的数据块（_tiddata)。虽然，线程有自己线程栈，线程可以直接访问全局变量，甚至可以访问进程地址空间中的每一个内存，所以一个线程可以读写甚至清楚另一个线程的堆栈。
3. 线程之间的通信比较方便。统一进程下的线程共享数据（比如全局变量，静态变量，打开的文件，子进程），通过这些数据来通信不仅快捷而且方便，当然如何处理好这些访问的同步与互斥正是编写多线程程序的难点。而进程之间的通信只能通过进程通信的方式进行。在一个线程中分配的堆在各个线程中均可以使用，在一个线程中打开的文件各个线程均可用，当然指同一进程中的线程。
4. 多进程比多线程程序要健壮。一个线程死掉整个进程就死掉了，但是在保护模式下，一个进程死掉对另一个进程没有直接影响。
5. 线程的执行与进程是有区别的。每个独立的线程有有自己的一个程序入口，顺序执行序列和程序的出口，但是线程不能独立执行，必须依附与程序之中，由应用程序提供多个线程的并发控制。
6. linux中进程具有父子关系，形成进程树，但是线程是平等的没有父子关系

### 1.6.0 fork进程
- 一个现有的进程可以通过fork函数来创建一个新的进程，这个进程通常称为子进程。fork函数原型如下：
```cpp
#include<unistd.h>
pid_t fork(void);
```
- 如果调用成功，它将返回两次，子进程返回值是0；父进程返回的是非0正值，表示子进程的进程id；如果调用失败将返回-1，并且置errno变量
- 一个进程可以有多个子进程，但是一个子进程同一时刻最多只有一个父进程。子进程可以通过getppid获取父进程的进程id，但是父进程却没法获取，因此需要在fork后就得到子进程的进程id。
### 1.7.0 fork做了什么？
- fork被调用后，子进程拥有父进程的副本，因此它拥有父进程的数据空间，堆栈等。
- 但是由于fork之后通常会调用exec函数去执行与原进程不想关的程序，因此fork时直接拷贝父进程的副本显得没有必要。为了提高fork的效率，采用了一种写时复制的技术。即fork之后，子进程名义上拥有父进程的副本，但是实际上和父进程共用，只有当父子进程中有一个试图修改这些区域时，才会以页为单位创建一个真正的副本。
### 1.7.1 fork和vfork的区别
在实现写时复制之前，Unix的设计者们就一直很关注在fork后立刻执行exec所造成的地址空间的浪费。BSD的开发者们在3.0的BSD系统中引入了vfork( )系统调用。
```cpp
#include <sys/types.h>
#include <unistd.h>
pid_t vfork(void);
```
除了子进程必须要立刻执行一次对exec的系统调用，或者调用_exit( )退出，对vfork( )的成功调用所产生的结果和fork( )是一样的。vfork( )会挂起父进程直到子进程终止或者运行了一个新的可执行文件的映像。通过这样的方式，vfork( )避免了地址空间的按页复制。在这个过程中，父进程和子进程共享相同的地址空间和页表项。实际上vfork( )只完成了一件事：复制内部的内核数据结构。因此，子进程也就不能修改地址空间中的任何内存。
vfork( )是一个历史遗留产物，Linux本不应该实现它。需要注意的是，即使增加了写时复制，vfork( )也要比fork( )快，因为它没有进行页表项的复制。然而，写时复制的出现减少了对于替换fork( )争论。实际上，直到2.2.0内核，vfork( )只是一个封装过的fork( )。因为对vfork( )的需求要小于fork( )，所以vfork( )的这种实现方式是可行的。
### 1.7.2 写时复制
Linux采用了写时复制的方法，以减少fork时对父进程空间进程整体复制带来的开销。

写时复制是一种采取了惰性优化方法来避免复制时的系统开销。它的前提很简单：如果有多个进程要读取它们自己的那部门资源的副本，那么复制是不必要的。每个进程只要保存一个指向这个资源的指针就可以了。只要没有进程要去修改自己的“副本”，就存在着这样的幻觉：每个进程好像独占那个资源。从而就避免了复制带来的负担。如果一个进程要修改自己的那份资源“副本”，那么就会复制那份资源，并把复制的那份提供给进程。不过其中的复制对进程来说是透明的。这个进程就可以修改复制后的资源了，同时其他的进程仍然共享那份没有修改过的资源。所以这就是名称的由来：在写入时进行复制。

写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。

在使用虚拟内存的情况下，写时复制（Copy-On-Write）是以页为基础进行的。所以，只要进程不修改它全部的地址空间，那么就不必复制整个地址空间。在fork( )调用结束后，父进程和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页又可以被其他的父进程或子进程共享。

写时复制在内核中的实现非常简单。与内核页相关的数据结构可以被标记为只读和写时复制。如果有进程试图修改一个页，就会产生一个缺页中断。内核处理缺页中断的方式就是对该页进行一次透明复制。这时会清除页面的COW属性，表示着它不再被共享。

现代的计算机系统结构中都在内存管理单元（MMU）提供了硬件级别的写时复制支持，所以实现是很容易的。

在调用fork( )时，写时复制是有很大优势的。因为大量的fork之后都会跟着执行exec，那么复制整个父进程地址空间中的内容到子进程的地址空间完全是在浪费时间：如果子进程立刻执行一个新的二进制可执行文件的映像，它先前的地址空间就会被交换出去。写时复制可以对这种情况进行优化。
### 1.7.3 fork和vfork的区别：
1. fork( )的子进程<font color='red'>拷贝</font>父进程的数据段和代码段；vfork( )的子进程与父进程<font color='red'>共享</font>数据段
2. fork( )的父子进程的<font color='red'>执行次序</font>不确定；vfork( )保证子进程先运行，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。
3. vfork( )保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。
4. 当需要改变共享数据段中变量的值，则拷贝父进程。
### 1.8. 子进程继承了父进程哪些属性？
由于子进程是父进程的一个副本，所以父进程有的属性，子进程也都有，这些属性包括
- 打开的文件描述符
- 会话ID
- 根目录
- 资源限制
- 工作目录
- 进程组ID
- 控制终端
- 环境
- …
### 1.9.父子进程有哪些不同？
- fork之后的返回值不同，进程ID也不同
- 子进程未处理信号设置为空
- 子进程不继承父进程设置的文件锁
- 一般子进程会执行与父进程不完全一样的代码流程

## 1.10 协程，
### 1.10.1 协程概念
又称微线程，纤程，英文名Coroutine。
协程（Coroutine，又称微线程）是一种比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制。

协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行，协程之间的切换不需要涉及任何系统调用或任何阻塞调用。

### 1.10.2 协程和线程区别
#### 1.10.2.1 可中断，不涉及阻塞调用
协程可以比作子程序，但执行过程中，子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。协程之间的切换不需要涉及任何系统调用或任何阻塞调用
#### 1.10.2.2 效率高，不需要切换
那和多线程比，协程最大的优势就是协程极高的执行效率。协程相比线程节省线程创建和切换的开销。
线程的阻塞状态是由操作系统内核来完成，发生在内核态上，协程只在一个线程中执行，是子程序之间的切换，发生在用户态上。
因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。
#### 1.10.2.3 不存在同时写变量冲突
第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。
### 1.10.3 协程 其他
在协程上利用多核CPU呢——多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。
Python对协程的支持还非常有限，用在generator中的yield可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。

### 1.10.4 协程适用于？
协程适用于IO阻塞且需要大量并发的场景，当发生IO阻塞，由协程的调度器进行调度，通过将数据流yield掉，并且记录当前栈上的数据，阻塞完后立刻再通过线程恢复栈，并把阻塞的结果放到这个线程上去运行。

# 二、进程间通信
### 2.1 进程间通信的方式
进程间通信主要包括
管道、
系统IPC（包括消息队列、信号量、信号、共享内存等）、
以及套接字socket。


### 2.1.1 普通管道PIPE：
> 管道主要包括无名管道和命名管道:
> 无名管道可用于具有亲缘关系的父子进程间的通信，
> 有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信
1. 它是**半双工**的（即数据只能在一个方向上流动），具有固定的读端和写端
2. 它只能用于具有亲缘关系的进程之间的通信（也是**父子进程**或者兄弟进程之间）
3. 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。
4. 使用popen函数和pclose函数结合来执行系统命令，就用到了管道

### 2.1.2 命名管道FIFO：
1. FIFO可以在无关的进程之间交换数据
2. FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。
3. `int mkfifo(const char *path, mode_t mode);`

### 2.1.3 系统IPC 消息队列
1. 消息队列，是消息的链表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。进程可以从中读写数据。
(消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点)
2. 具有写权限得进程可以按照一定得规则向消息队列中添加新信息；
3. 对消息队列有读权限得进程则可以从消息队列中读取信息；
4. 与管道和FIFO不同，进程可以在没有另外一个进程等待读的情况下进行写。但是对于消息队列，一个进程往消息队列中写入数据后退出，另外一个进程仍然可以打开并读取消息。

特点：
1. 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。
2. 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。
3. 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。

### 2.2.4 系统IPC 信号量semaphore
信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。
特点：

1. 提供了一个不同进程或者进程的不同线程之间访问同步的手段:
2. 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。检查控制该资源的信号量
3. 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。
4. 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。如果信号量值大于0，则资源可用，并且将其减1，表示当前已被使用
5. 支持信号量组。
6. 如果信号量值为0，则进程休眠直至信号量值大于0

### 2.2.5 系统IPC 信号signal
信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

### 2.2.6 系统IPC 共享内存（Shared Memory）
它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等
特点：

1. 共享内存是最快的一种IPC，因为进程是直接对内存进行存取
2. 因为多个进程可以同时操作，所以需要进行同步
3. 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问
4. 允许多个进程共享一个给定的存储区，
### 2.2.7 UNXI域套接字
- 不需要执行协议处理，例如计算校验和，发送确认报文等等，它仅仅复制数据。
- 只适用于同一台计算机上的进程间通信
### 2.2.8 套接字SOCKET：
socket也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。

### 2.2 线程间通信的方式:
* 临界区：
  - 通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；
* 互斥量Synchronized/Lock：
  - 采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
* 信号量Semphare：
  - 为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。
* 事件(信号)，Wait/Notify：
  - 通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作;线程可以设置或等待事件。当事件被设置时，等待该事件的一个或多个线程将被唤醒。
  
原子操作：使用原子操作可以在不使用锁的情况下对共享数据进行操作，这样可以避免竞态条件。
屏障（Barriers）：允许多个线程在某个点上同步。当所有线程都到达屏障时，它们将同时继续执行。

条件变量（Condition Variable）：条件变量是一种线程同步的机制，用于线程间的等待和通知。线程可以通过条件变量等待某个条件的满足，当条件满足时，其他线程可以通过条件变量发出通知，唤醒等待的线程。
共享内存：线程可以通过读写共享内存中的变量或数据结构来通信。为了防止数据竞争和不一致，通常需要使用互斥量（mutexes）或其他同步原语进行保护。
管道（Pipes）：虽然通常用于进程间通信，但它们也可以用于线程间通信。一个线程向管道写数据，而另一个线程从管道读数据。
消息队列：线程将消息发送到队列，其他线程可以从队列中读取消息。这是一种避免共享数据并减少同步问题的方法。

## 2.3 为什么用进程间通信？
### 2.3.1 进程间通信 背景
- 进程是一个独立的资源分配单元，不同进程（这里所说的进程通常指的是用户进程）之间的资源是独立的，没有关联，不能在一个进程中直接访问另一个进程的资源（例如打开的文件描述符）。
- 但是，进程不是孤立的，不同的进程需要进行信息的交互和状态的传递等，因此需要进程间通信( IPC：Inter Processes Communication )。
### 2.3.2 进程间通信 目的
#### 2.3.2.1 <font color='red'>数据传输：</font>
一个进程需要将它的数据发送给另一个进程。
#### 2.3.2.2 <font color='red'>通知事件：</font>
一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。
#### 2.3.2.3 <font color='red'>资源共享：</font>
多个进程之间共享同样的资源。为了做到这一点，需要内核提供互斥和同步机制。
#### 2.3.2.4 <font color='red'>进程控制：</font>
有些进程希望完全控制另一个进程的执行（如 Debug 进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。
### 2.4 为什么用共享内存
- 为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。
- 共享内存区时可用IPC形式中最快的。内存区共享它的进程的地址空间，进程间的数据传递不再涉及内核。绕过内核。
# 三、操作系统
### 3.0 操作系统
## 3.1 操作系统中的程序的内存结构
## 3.2 缺页中断
## 3.3 修改文件最大句柄数？
1. ulimit -n <可以同时打开的文件数>
2. vi /etc/security/limits.conf

### 3.4 并发(concurrency)和并行(parallelism)
并发（concurrency）：
- 指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。

并行（parallelism）：
- 指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展

## 3.5 死锁
### 3.5.1 死锁原因
在死锁时，线程/进程间相互等待资源，而又不释放自身的资源，导致无穷无尽的等待，其结果是任务永远无法执行完成。
如果一组进程中每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么该组进程是死锁的。

### 3.5.2 死锁必要条件
#### 1.互斥：
某资源只能被一个进程使用，其他进程请求时，只能等待，直到资源使用完毕后释放
#### 2.请求和保持条件，占有且申请：
至少保持了一个资源，又提出新要求，而这个资源被其他进程占用，自己占用却不释放
#### 3.不剥夺条件，不可抢占：
任何一个资源在没被该进程释放之前，任何其他进程都无法对他剥夺占用
#### 4.循环等待条件：
当发生死锁时，所等待的进程必定会形成一个环路（类似于死循环），造成永久阻塞
### 3.5.3 死锁避免
1.尽量避免同时只对一个互斥锁上锁
2.互斥锁保护区域不要使用操作其他互斥锁的代码，因为用户的代码可能操作了其他的互斥锁
3.如果想同时对多个互斥锁上锁，要使用std::lock(my_mutex_1, my_mutex_2);一旦有一个互斥量不能被锁，线程就会卡在这里，直至两个锁可以被同时锁成功，
4.给锁定义顺序（使用层次锁，或者比较地址等），每次以同样的顺序进行上锁

### 3.5.4 死锁处理
破坏除了互斥以外的死锁必要条件（打破互斥即使可以同时访问，无价值。）
#### 3.5.4.1 <font color='red'>打破不可抢占</font>，
允许<font color='red'>强行从占有者那里夺取资源</font>。（一个进程已占有但不能满足时要释放资源重新申请。）降低系统性能；
#### 3.5.4.2 打破占有且申请，
资源预先分配，<font color='red'>一次性申请全部资源</font>，不满足则不申请不运行，
缺点：
1).许多情况下并不知道它需要的全部资源，动态的，不可预测的
2).资源利用率低，资源一直被长期占用，浪费资源
3).降低并发性，资源有限+浪费，能分配到全部资源的进程少

#### 3.5.4.3 打破循环等待条件
实行<font color='red'>资源有序分配策略</font>。采用这种策略，即把资源事先分类编号，按号分配，使进程在申请，占用资源时不会形成环路。所有进程对资源的请求必须严格按资源序号递增的顺序提出。进程占用了小号资源，才能申请大号资源，就不会产生环路，从而预防了死锁。
缺点：
1).限制进程对资源的请求，同时合理编号比较难，增加系统开销
2).为遵循编号次序，暂时不使用也需要提前申请，从而增加了进程对资源的占用时间。
#### 避免
在资源动态分配过程中，用某种方式防止系统进入不安全的状态
#### 检测
运行时出现死锁，能及时发现死锁，
#### 解除
解脱进程，通常撤销进程，回收资源，再分配给正处于阻塞状态的进程。

### 3.6 为什么用线程池？
#### 3.6.1 创建资源
1. 线程创建所需时间为T1，线程执行任务时间为T2，线程销毁时间为T3，而往往T1+T3>T2。所以频繁创建线程会损坏而外的时间。
2. 如果有任务来了，再去创建线程的话效率比较低。
3. 线程池可以管理控制线程，线程是稀缺资源，如果无休止的创建会消耗系统资源，还会降低系统稳定性。使用线程池可以进行统一分配，方便调优和监控。
4. 线程池提供队列，存放缓冲等待执行任务。
### 3.6.2 线程池通常适合下面的几个场合：
1. 单位时间内处理的任务数较多，且每个任务的执行时间较短
2. 对实时性要求较高的任务，如果接受到任务后在创建线程，再执行任务，可能满足不了实时要求，因此必须采用线程池进行预创建。

## 3.7 生产者消费者模型
### 3.7.1 生产者消费者模型 解耦
- 需要有一个交易场所。（存储数据的地方，可能是一个队列、栈或者其他数据结构）
- 生产者：负责产生数据，然后把数据放到交易场所中。
- 消费者：负责消费数据，从交易场所中获取走。
- 通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。这个阻塞队列就是用来给生产者和消费者解耦的。
### 3.7.2 生产者消费者模型 优点
  * 解耦
  * 并发
  * 忙闲不均
在生产者消费者模型中，生产者和消费者之间通过共享的缓冲区进行通信。当生产者生成数据时，将数据放入缓冲区；当消费者需要消费数据时，从缓冲区中取出数据。通过合理地设计缓冲区的大小，可以使生产者和消费者之间的速度不匹配问题得到缓解。
当生产者生成数据的速度快于消费者消费数据的速度时，生产者可以将数据放入缓冲区并继续生成下一个数据，而不需要等待消费者消费。这样，生产者可以保持较高的工作效率，不会因为消费者速度慢而空闲等待。
同时，消费者可以按照自己的处理能力从缓冲区中取出数据进行消费，而不会受到生产者速度快的影响。消费者可以根据自己的处理能力合理安排消费数据的速度，不会因为生产者速度快而导致数据堆积或丢失。
因此，生产者消费者模型的忙闲不均特性使得生产者和消费者能够在各自的最大工作效率下进行工作，提高了多线程程序的整体性能。

### 3.7.3 生产者消费者模型 三种关系：
  * 消费者和消费者之间是互斥关系。两个消费者只有一个能拥有数据。
  * 生产者和生产者之间是互斥关系。两个生产者只有一个可以往里面存数据，不能同时存。
  * 生产者和消费者之间是同步互斥的关系。生产者和消费者必须按照一定的顺序执行。

### 3.8 Linux的4种锁机制：
mutex rwlock spinlock RCU
### 3.8.0 锁被释放时，唤醒的方式？
当多个线程试图获取同一互斥锁（mutex）时，只有一个线程能成功获取，其他的线程将被阻塞（即进入睡眠状态），等待该锁被释放。
当互斥锁被释放时，阻塞的线程通常会被唤醒来竞争该锁。但具体哪个线程能成功获取这个锁，或者说是否所有等待的线程都会被唤醒，这取决于操作系统的调度策略。
一些系统可能会选择只唤醒一个线程，让它获取锁。这被称为"唤醒一个"（waking one）策略。其他系统可能会选择唤醒所有等待的线程，并让它们竞争获取锁，这被称为"唤醒所有"（waking all）或 "thundering herd"策略。
"唤醒一个"策略可能更有效率，因为它避免了不必要的竞争。但"唤醒所有"策略可能在某些情况下更公平，尽管可能会导致资源竞争更激烈。
无论哪种策略，应用程序通常不需要（也不应该）关心这些细节。重要的是正确地使用互斥锁来保护对共享数据的访问，避免数据竞争和死锁。

### 3.8.1 互斥锁：mutex，
用于保证在**任何时刻，都只能有一个线程**访问该对象。
当获取锁操作失败时，线程会**进入睡眠，等待锁释放时被唤醒**

### 3.8.2 读写锁：rwlock，分为读锁和写锁。
处于读操作时，可以允许**多个线程同时获得读**操作。
但是同一时刻**只能有一个线程可以获得写锁**。其它获取写锁失败的线程都会**进入睡眠状态，直到写锁释放时被唤醒**。
注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。
适用于读取数据的频率远远大于写数据的频率的场合。
### 3.8.3 自旋锁：spinlock，
在任何时刻同样**只能有一个线程访问对象**。
但是当获取锁操作失败时，**不会进入睡眠，而是会在原地自旋**，直到锁被释放。
这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。

### 3.8.4 RCU：即read-copy-update，
在修改数据时，首先需要读取数据，然后**生成一个副本，对副本进行修改**。
修改完成后，再将老数据update成新的数据。
使用RCU时，读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。
而对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少量写操作的情况下效率非常高。

### 3.9 互斥锁和读写锁区别：

互斥锁：当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

读写锁：rwlock，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 

1）读写锁区分读者和写者，而互斥锁不区分
2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。

### 3.10 用户态和内核态区别
用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。
用户态拥有最低的特权级，内核态拥有较高的特权级。
运行在用户态的程序不能直接访问操作系统内核数据结构和程序。内核态和用户态之间的转换方式主要包括：系统调用，异常和中断。

## 3.11 系统调用是什么，你用过哪些系统调用
### 3.11.1 系统调用 概念：
在计算机中，系统调用（英语：system call），又称为系统呼叫，指运行在使用者空间的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供了用户程序与操作系统之间的接口（即系统调用是用户程序和内核交互的接口）。
操作系统中的状态分为管态（核心态）和目态（用户态）。大多数系统交互式操作需求在内核态执行。如设备IO操作或者进程间通信。特权指令：一类只能在核心态下运行而不能在用户态下运行的特殊指令。不同的操作系统特权指令会有所差异，但是一般来说主要是和硬件相关的一些指令。用户程序只在用户态下运行，有时需要访问系统核心功能，这时通过系统调用接口使用系统调用。
应用程序有时会需要一些危险的、权限很高的指令，如果把这些权限放心地交给用户程序是很危险的(比如一个进程可能修改另一个进程的内存区，导致其不能运行)，但是又不能完全不给这些权限。于是有了系统调用，危险的指令被包装成系统调用，用户程序只能调用而无权自己运行那些危险的指令。另外，计算机硬件的资源是有限的，为了更好的管理这些资源，所有的资源都由操作系统控制，进程只能向操作系统请求这些资源。操作系统是这些资源的唯一入口，这个入口就是系统调用。

### 3.11.2 系统调用举例：
open和write都是系统调用。
还有写数据write，创建进程fork，vfork等都是系统调用。

## 3.12 请你来说一说用户态到内核态的转化原理
### 3.12.1 用户态切换到内核态的3种方式
#### 3.12.1.1、系统调用
这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的ine 80h中断。
#### 3.12.1.2、异常
当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。
#### 3.12.1.3、外围设备的中断
当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

### 3.12.2 用户态切换到内核态 切换操作
CPU中有一个标志字段，标志着线程的运行状态。用户态和内核态对应着不同的值，**用户态为3，内核态为0.**

**每个线程**都对应着一个**用户栈和内核栈**，分别用来执行**用户方法和内核方法**。
用户方法就是普通的操作。
内核方法就是访问磁盘、内存分配、网卡、声卡等敏感操作。

当用户**尝试调用内核方法**的时候，就会发生用户态切换到内核态的转变。

1用户态进程通过一个特殊的 CPU 指令（例如，在 x86 架构中的 int 指令）引发一个软件中断。
2软件中断使 CPU 切换到内核态，并跳转到预定的内核代码。
3内核代码（即系统调用的处理代码）执行请求的操作。
4当操作完成后，内核代码使用另一种特殊的 CPU 指令（例如，在 x86 架构中的 iret 指令）返回到用户态，并跳转回原来的用户代码。
整个过程中，操作系统内核负责保存和恢复用户进程的状态，以使用户进程不会意识到这种模式的切换。

切换流程：
1、每个线程都对应这一个TCB，**TCB中有一个TSS字段**，存储着**线程对应的内核栈的地址**，也就是**内核栈的栈顶指针**。
2、因为从用户态切换到内核态时，需要将**用户态对应的CPU现场信息保存起来**啊，这些信息对应着当前**用户栈的执行状态**，也就是当前用户态执行到哪一步了，方便后续的恢复。
所以会将CPU中关于当前用户栈的信息，也就是**各类寄存器信息**，包括**PC寄存器**信息写入到**内核栈**中，方便后续内核方法调用完毕后，**恢复用户方法执行的现场**。
3、将CPU的字段改为**内核态**，将**内核段对应的代码地址写入到PC寄存器**中，然后**开始执行内核方法**，相应的方法栈帧时保存在**内核栈**中。
4、当内核方法执行完毕后，会将**CPU的字段改为用户态**，然后利用之前写入的信息来**恢复用户栈的执行**。
从上述流程可以看出用户态切换到内核态的时候，会牵扯到用户态现场信息的保存以及恢复，还要进行一系列的安全检查，比较耗费资源。

下面是一些可能的改变：

1.`Program Counter(PC)`：程序计数器保存着线程需要下一步执行的指令的地址。在系统调用发生时，PC会被改变以指向系统调用的处理代码。当系统调用结束后，PC会被恢复为原来的值，以便线程可以继续执行用户态代码。
2.`Processor State`：这部分保存了线程的一些状态信息，包括寄存器的值，优先级，以及其他状态信息。在进行系统调用时，操作系统会保存这些信息以便在系统调用结束后可以恢复线程的状态。
3.`Process State`：线程的状态（例如，运行，就绪，阻塞等）可能会在进行系统调用时发生改变。例如，如果一个线程发出了一个读取文件的系统调用，那么在文件读取完成之前，这个线程可能会被标记为阻塞状态。

从出发方式看，可以在认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一样的，没有任何区别，都相当于执行了一个中断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断处理机制基本上是一样的，用户态切换到内核态的步骤主要包括：
1、从当前进程的描述符中提取其内核栈的ss0及esp0信息。
2、使用ss0和esp0指向的内核栈将当前进程的cs,eip，eflags，ss,esp信息保存起来，这个过程也完成了由用户栈找到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。
3、将先前由中断向量检索得到的中断处理程序的cs，eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。

### 3.13 请你来说一下微内核与宏内核
#### 3.13.1 宏内核：
除了最基本的进程、线程管理、内存管理外，将文件系统，驱动，网络协议等等都集成在内核里面，例如linux内核。
#### 3.13.1.1 优点：
效率高。
#### 3.13.1.2 缺点：
稳定性差，开发过程中的bug经常会导致整个系统挂掉。

#### 3.13.2 微内核：
内核中只有最基本的调度、内存管理。驱动、文件系统等都是用户态的守护进程去实现的。
#### 3.13.2.1 优点：
稳定，驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃
#### 3.13.2.2 缺点：
效率低。典型代表QNX，QNX的文件系统是跑在用户态的进程，称为resmgr的东西，是订阅发布机制，文件系统的错误只会导致这个守护进程挂掉。不过数据吞吐量就比较不乐观了。

## 3.14 僵尸进程
### 3.14.1 正常进程
正常情况下，子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。
unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。 但是仍然为其保留一定的信息，直到父进程通过wait / waitpid来取时才释放。保存信息包括：

1. 进程号the process ID
2. 退出状态the termination status of the process
3. 运行时间the amount of CPU time taken by the process等

### 3.14.2 孤儿进程
一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
### 3.14.3 僵尸进程
一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。
僵尸进程是一个进程必然会经过的过程：这是每个子进程在结束时都要经过的阶段。
如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。
如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。

### 3.14.4 僵尸进程危害：
如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。
### 3.14.5 僵尸进程外部消灭：
通过kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源
### 3.14.6 僵尸进程内部解决：
1. 子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。
2. fork两次，原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。

# 四、 C++线程
### 4.1 创建线程调用方式
#### 4.1.1 函数指针
```cpp
// 1.函数指针
void fun(int x) {
    while (x-- > 0) {
        cout << x << endl;
    }
}
// 调用
std::thread t1(fun, 10);
t1.join();
```
#### 4.1.2 Lambda函数
```cpp
// 注意：如果我们创建多线程 并不会保证哪一个先开始
int main() {
    // 2.Lambda函数
    auto fun = [](int x) {
        while (x-- > 0) {
            cout << x << endl;
        }
    };
//    std::1.thread t1(fun, 10);
    // 也可以写成下面：
    std::thread t1_1([](int x) {
        while (x-- > 0) {
            cout << x << endl;
        }
    }, 11);
//    std::1.thread t2(fun, 10);
//    t1.join();
    t1_1.join();
//    t2.join();
    return 0;
}
```
#### 4.1.3 仿函数
```cpp
// 3.functor (Funciton Object)
class Base {
public:
    void operator()(int x) {
        while (x-- > 0) {
            cout << x << endl;
        }
    }
};
// 调用
thread t(Base(), 10);
t.join();
```
#### 4.1.4 非静态成员函数
```c++
// 4.Non-static member function
class Base {
public:
    void fun(int x) {
        while (x-- > 0) {
            cout << x << endl;
        }
    }
};
// 调用
thread t(&Base::fun,&b, 10);
t.join();
```
#### 4.1.5 静态成员函数
```cpp
// 5.static member function
class Base {
public:
    static void fun(int x) {
        while (x-- > 0) {
            cout << x << endl;
        }
    }
};
// 调用
thread t(&Base::fun, 10);
t.join();
```
### 4.2 mutex互斥量
参见 ：
[c++之多线程中“锁”的基本用法
](https://zhuanlan.zhihu.com/p/91062516)
[C++多线程开发之互斥锁](https://light-city.club/sc/concurrency/Threading_In_CPlusPlus/thread/#2)

#### 4.2.1 mutex无锁情况
```cpp
#include <iostream>
#include <mutex>
#include <thread>

using namespace std;

int sum = 0; //shared

void *countgold()
{
    int i; //local to each thread
    for (i = 0; i < 10000000; i++) {
        sum += 1;
    }
    return NULL;
}

int main()
{
    thread t1(countgold);
    thread t2(countgold);

    //Wait for both threads to finish
    t1.join();
    t2.join();

    cout << "sum = " << sum << endl;
    return 0;
}
➜  thread ./mutex_demo1_no_mutex
sum = 19131716
➜  thread ./mutex_demo1_no_mutex
sum = 20000000
➜  thread ./mutex_demo1_no_mutex
sum = 18729155
```
#### 4.2.2 使用mutex加锁
```cpp
#include <iostream>
#include <thread>
#include <vector>
#include <mutex>
#include <chrono>
#include <stdexcept>

int sum = 0; //shared
int counter = 0;
std::mutex mtx;

void increase(int time)
{
    for (int i = 0; i < time; i++)
    {
        mtx.lock();
        counter+=1;
        mtx.unlock();
    }
}

void *countgold()
{
    int i; //local to each thread
    for (i = 0; i < 10000000; i++) {
        sum += 1;
    }
    return NULL;
}

int main(int argc, char** argv)
{
    std::cout << "sum = " << sum << std::endl;
    std::cout << "counter:" << counter << std::endl;
    std::thread t1(increase, 10000000);
    std::thread t2(increase, 10000000);
    t1.join();
    t2.join();

    std::thread t3(countgold);
    std::thread t4(countgold);

    //Wait for both threads to finish
    t3.join();
    t4.join();

    std::cout << "sum = " << sum << std::endl;
    std::cout << "counter:" << counter << std::endl;
    return 0;
}
➜  thread ./mutex_demo2_with_mutex
sum = 0
counter:0
sum = 19366730
counter:20000000
➜  thread ./mutex_demo2_with_mutex
sum = 0
counter:0
sum = 19666435
counter:20000000
```
#### 4.2.3 总结使用mutex

1. 对于std::mutex对象，任意时刻最多允许一个线程对其进行上锁
2. mtx.lock()：调用该函数的线程尝试加锁。如果上锁不成功，即：其它线程已经上锁且未释放，则当前线程block。如果上锁成功，则执行后面的操作，操作完成后要调用mtx.unlock()释放锁，否则会导致死锁的产生
3. mtx.unlock()：释放锁
4. std::mutex还有一个操作：mtx.try_lock()，字面意思就是：“尝试上锁”，与mtx.lock()的不同点在于：如果上锁不成功，当前线程不阻塞。

## 4.3 lock_guard
### 4.3.1 死锁
```cpp
#include <functional>
#include <iostream>
#include <thread>
#include <vector>
#include <mutex>
#include <chrono>
#include <stdexcept>

int counter  = 0;
int counter2 = 0;
std::mutex mtx;

#define TEST 1
#if TEST
void increase(int time)
{
    for (int i = 0; i < time; i++)
    {
        mtx.lock();
        counter+=1;
        mtx.unlock();
    }
}
#endif

void increase_proxy(int time, int id)
{
    for (int i = 0; i < time; i++)
    {
        mtx.lock();
        // 线程1上锁成功后，抛出异常：未释放锁
        if (id == 1)
        {
            throw std::runtime_error("throw excption....");
        }
        counter2++;
        mtx.unlock();
    }
}
void increase(int time, int id)
{
    try
    {
        for (int i = 0; i < time; i++)
        {
            mtx.lock();
            // 线程1上锁成功后，抛出异常：未释放锁
            if (id == 1)
            {
                throw std::runtime_error("throw excption....");
            }
            counter2++;
            mtx.unlock();
        }
        //increase_proxy(time, id);
    }
    catch (const std::exception& e)
    {
        std::cout << "id:" << id << ", " << e.what() << std::endl;
    }
}

int main(int argc, char** argv)
{
#if TEST
    std::cout << "counter:" << counter << std::endl;
//    auto func = increace();
    std::function<void(int)>     f1 = [] (int a) { return increase(a); };
    std::function<void(int,int)> f2 = [] (int a,int b) { return increase(a,b); };

    std::thread t1(f1, 10000000);
    std::thread t2(f1, 10000000);
    t1.join();
    t2.join();
    std::cout << "counter:" << counter << std::endl;
#endif

    std::cout << "counter2:" << counter2 << std::endl;
    std::thread t3(f2, 10000000, 1);
    std::thread t4(f2, 10000000, 2);
    t3.join();
    t4.join();

    std::cout << "counter2:" << counter2 << std::endl;
    return 0;
}

➜  thread ./mutex_demo3_dead_lock
counter:0
counter:20000000
counter2:0
id:1, throw excption....
```
- 没有退出，发生死锁
- std::lock_guard只有构造函数和析构函数。
    * 简单的来说：当调用构造函数时，会自动调用传入的对象的lock()函数，而当调用析构函数时，自动调用unlock()函数（这就是所谓的RAII，读者可自行搜索）。

### 4.3.2 lock_guard 避免死锁
```cpp
#include <functional>
#include <iostream>
#include <thread>
#include <vector>
#include <mutex>
#include <chrono>
#include <stdexcept>

int counter  = 0;
int counter2 = 0;
std::mutex mtx;

void increase(int time)
{
    for (int i = 0; i < time; i++)
    {
        counter+=1;
    }
}

void increase(int time, int id)
{
    try
    {
        for (int i = 0; i < time; i++)
        {
            // 不再使用 mtx.lock();替换为 lock_guard
            // std::lock_guard对象构造时，自动调用mtx.lock()进行上锁
            // std::lock_guard对象析构时，自动调用mtx.unlock()释放锁
            std::lock_guard<std::mutex> lk(mtx);
            // 线程1上锁成功后，抛出异常：未释放锁
            if (id == 1)
            {
                throw std::runtime_error("throw excption....");
            }
            counter2++;
        }
    }
    catch (const std::exception& e)
    {
        std::cout << "id:" << id << ", " << e.what() << std::endl;
    }
}

int main(int argc, char** argv)
{
    std::cout << "counter:" << counter << std::endl;
    std::function<void(int)>     f1 = [] (int a) { return increase(a); };
    std::function<void(int,int)> f2 = [] (int a,int b) { return increase(a,b); };

    std::thread t1(f1, 10000000);
    std::thread t2(f1, 10000000);
    t1.join();
    t2.join();
    std::cout << "counter:" << counter << std::endl;

    std::cout << "counter2:" << counter2 << std::endl;
    std::thread t3(f2, 10000000, 1);
    std::thread t4(f2, 10000000, 2);
    t3.join();
    t4.join();

    std::cout << "counter2:" << counter2 << std::endl;
    return 0;
}

➜  thread ./mutex_demo4_lock_guard
counter:0
counter:15638387
counter2:0
id:1, throw excption....
counter2:10000000
```
- 结果符合预期。所以，推荐使用std::mutex和std::lock_guard搭配使用，避免死锁的发生。

# 五、 pthread线程

### 5.1 pthread线程 mutex互斥量
```
#include <pthread.h>
#include <thread>
```
此外，依据同一线程是否能多次加锁，把互斥量又分为如下两类：

是：称为『递归互斥量』recursive mutex ，也称『可重入锁』reentrant lock
否：即『非递归互斥量』non-recursive mute），也称『不可重入锁』non-reentrant mutex

C++ 递归互斥量的API： std::recursive_mutex
pthread则可以通过给mutex添加 PTHREAD_MUTEX_RECURSIVE

### 5.2 condition variable（条件变量）
C++11中也有条件变量的API： std::condition_variable。
pthread 条件变量 pthread_cond_t

[涛哥 线程间同步互斥（3）条件变量使用](https://zhuanlan.zhihu.com/p/136431212)
[飞翔的猪 再谈条件变量—从入门到出家](https://zhuanlan.zhihu.com/p/155547997)
[暗淡了乌云 条件变量 之 稀里糊涂的锁](https://zhuanlan.zhihu.com/p/55123862)
[好物推荐到火星 条件变量pthread API编程小练习](https://zhuanlan.zhihu.com/p/51387442)
[关于一点pthread_cond_t条件锁的思考以及实验](https://www.cnblogs.com/liulipeng/p/3552767.html)
[pthread_mutex_t 和 pthread_cond_t 配合使用的简要分析](https://blog.csdn.net/chengonghao/article/details/51779279)

### 5.3 read-write lock（读写锁）
共享-独占锁
读共享，写独占的锁
允许多个线程同时读数据，而写数据则必须保证没有其他线程在读写。

// 声明一个读写锁 pthread_rwlock_t | 静态分配的读写锁，可以用常值PTHREAD_\RWLOCK_INITIALIZER来初始化 | 调用pthread_rwlock_init来动态初始化
pthread_rwlockattr_setkind_np用来设置writer或者reader优先权，缺省设置是PTHREAD_RWLOCK_PREFER_READER_NP，也就是reader优先进入lock队列，这会造成writer饿死；
另外的设置是PTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NP，它可以解决writer饿死的问题，具体实现是writer在获得lock前会阻止reader继续进入lock队列，解决writer的问题同时，它也会造成reader饿死可能。
C++17 std::shared_mutex 模拟实现出读写锁
```cpp
// 初始化读写锁
int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr);
// 获得读锁，如果此时其他线程已经获得了写锁，那么会等待
int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);
// 获得写锁，如果此时其他线程已经获得读锁或写锁，那么会等待
int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);
// 释放读锁或写锁
int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);
// 结束读写锁
int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);
```

[线程间同步互斥（2）读写锁使用 涛哥](https://zhuanlan.zhihu.com/p/135983375)

### 5.4 spinlock（自旋锁）
『忙等待』（busy waiting） 死循环
当共享资源的状态不满足的时候，自旋锁会不停地循环检测状态.因为不会陷入休眠，而是忙等待的方式也就不需要条件变量。
不休眠就不会引起上下文切换，但是会比较浪费CPU。
在中断上下文，是不允许睡眠的，所以，这里需要的是一个不会导致睡眠的锁——spinlock。
换言之，中断上下文要用锁，首选 spinlock。

pthread_spin_init 函数的第二个参数名为pshared（int类型）
- PTHREAD_PROCESS_PRIVATE：仅同进程下读线程可以使用该自旋锁
- PTHREAD_PROCESS_SHARED：不同进程下的线程可以使用该自旋锁

### 5.5 信号量(semaphore)
```cp
#include <semaphore.h>
// 初始化信号量
int sem_init(sem_t *sem, int pshared, unsigned int value);
// 信号量 P 操作（减 1）
int sem_wait(sem_t *sem);
// 以非阻塞的方式来对信号量进行减 1 操作
int sem_trywait(sem_t *sem);
// 信号量 V 操作（加 1）
int sem_post(sem_t *sem);
// 获取信号量的值
int sem_getvalue(sem_t *sem, int *sval);
// 销毁信号量
int sem_destroy(sem_t *sem);
```
[详解linux多线程——互斥锁、条件变量、读写锁、自旋锁、信号量](https://zhuanlan.zhihu.com/p/161010435)

